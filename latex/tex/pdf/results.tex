\section{Implementation and Results}%
\label{sec:pdf_results}

The considerations of \cref{sec:pdf_basics,sec:lab_xs} can now be
applied to obtain a cross section and histograms of observables for
the scattering of two protons into two photons. Because the PDF is not
available in closed form, event generation is the only viable way to
obtain distributions of observables and verify theory against
experiment, even with this simple leading-order process.

The integrand in \cref{eq:pdf-xs} can be concertized into
\cref{eq:weighteddist}, where \(q\) runs over all quarks (except the
top quark). The sum has been symmetized, otherwise a double sum with
\(q\) and \(\bar{q}\) would have been necessary. The choice of \(Q^2\)
is justified in \cref{sec:pdf_basics} and formulated in
\cref{eq:q2-explicit}.
%
\begin{gather}
  \label{eq:weighteddist}
  \frac{\dd[3]{\sigma}}{\dd{\eta}\dd{x_1}\dd{x_2}} =
  \sum_q \qty[f_q\qty(x_1;Q^2) f_{\bar{q}}\qty(x_2;Q^2) + f_q\qty(x_2;Q^2) f_{\bar{q}}\qty(x_1;Q^2)] \dv{\sigma(x_1,
    x_2, Z_q)}{\eta} \\
  \label{eq:q2-explicit}
  Q^2 = 2x_1x_2E_p^2
\end{gather}
%
The PDF set being used in the following has been fitted (and
\emph{DGLAP} developed) at leading order and is the central member of
the PDF set \verb|NNPDF31_lo_as_0118| provided by \emph{NNPDF}
collaboration and accessed through the \lhapdf\
library~\cite{NNPDF:2017pd,Buckley:2015lh}.

\subsection{Cross Section}%
\label{sec:ppxs}

The distribution \cref{eq:weighteddist} can now be integrated to
obtain a total cross-section as described in \cref{sec:mcint}.  For
the numeric analysis a proton beam energy of
\result{xs/python/pdf/e_proton} has been chosen, in resemblance to
\lhc{} beam energies. The cuts \result{xs/python/pdf/eta} and
\result{xs/python/pdf/min_pT} have been imposed. Integrating
\cref{eq:weighteddist} with respect to those cuts using \vegas\ yields
\result{xs/python/pdf/my_sigma} which is compatible with
\result{xs/python/pdf/sherpa_sigma}, the value \sherpa\ gives.

\subsection{Event Generation and Histograms}%
\label{sec:ppevents}

Generating events of \(\ppgg\) is very similar in principle to
sampling the partonic cross section. As before, the range of the
\(\eta\) parameter has to be constrained to obtain physical
results. Because the absolute values of the pseudo rapidities of the
two final state photons are not equal in the lab frame, the shape of
the integration/sampling volume differs from a simple hypercube
\(\Omega\). Furthermore, for the massless limit to be applicable the
center of mass energy of the partonic system must be much greater than
the quark masses. This can be implemented by demanding the transverse
momentum \(p_T\) of a final state photon to be greater
than~\SI{20}{\giga\electronvolt}. A restriction (cut) on \(p_T\) is
suitable because detectors are usually only sensitive above a certain
\(p_T\) threshold and the final state particles have to be isolated
from the beams.

The resulting distribution (without cuts) is depicted in
\cref{fig:dist-pdf} for fixed \(x_2\) and in
\cref{fig:dist-pdf-fixed-eta} for fixed \(\eta\). For \(x_1 = x_2\)
the distribution retains some likeness with the partonic distribution
(see \cref{fig:xs-int-eta}) but gets suppressed for greater values of
\(x_1\). The overall shape of the distribution is clearly highly
sub-optimal for hit-or-miss sampling, only having significant magnitude
when \(x_1\) or \(x_2\) are small (\cref{fig:dist-pdf-fixed-eta}) and
being very steep.
%
\begin{figure}[ht]
  \centering
  \begin{subfigure}{1\textwidth}
    \centering \plot{pdf/dist3d_x2_const}
    \caption{\label{fig:dist-pdf}Differential cross section convolved
      with PDFs for fixed \protect \result{xs/python/pdf/second_x} in
      picobarn.}
  \end{subfigure}
%
  \begin{subfigure}{1\textwidth}
    \centering \plot{pdf/dist3d_eta_const}
    \caption{\label{fig:dist-pdf-fixed-eta}Differential cross section
      convolved with PDFs for fixed \protect
      \result{xs/python/pdf/plot_eta} in picobarn.}
  \end{subfigure}
  \caption{\label{fig:dist-pdf-3d}Differential cross section
    convolved with PDFs with one parameter fixed.}
\end{figure}
%
To remedy that, one has to use a more efficient sampling algorithm
(\vegas) or impose very restrictive cuts. The self-coded
implementation used here can be found in \cref{sec:pycode} and employs
stratified sampling (as discussed in \cref{sec:stratsamp-real}) and
the hit-or-miss method. The matrix element (ME) and cuts are
implemented using \texttt{cython}~\cite{behnel2011:cy} to obtain
better performance as these are evaluated very often. The ME and the
cuts are then convolved with the PDF (as in \cref{eq:weighteddist})
and wrapped into a simple function with a generic interface and
plugged into the \vegas\ implementation which then computes the
integral, grid, individual contributions to the grid and rough
estimates of the maxima in each hypercube. In principle the code could
be generalized to other processes by simply redefining the matrix
elements, as no other part of the code is process specific. The cuts
work as simple \(\theta\)-functions, which has the advantage, that the
maximum for hit or miss can be chosen with respect to those cuts. On
the other hand, this method introduces discontinuity into the
integrand, which is problematic for numeric maximizers.  The estimates
of the maxima, provided by the \vegas\ implementation used as the
starting point for a gradient ascend maximizer. In this way, the
discontinuities introduced by the cuts got circumvented. Because the
stratified sampling requires very accurate upper bounds, they have
been overestimated by \result{xs/python/pdf/overesimate}\!, which
lowers the efficiency slightly but reduces bias. The sampling
algorithm chooses hypercubes randomly in accordance to their
contribution to the integral by generating a uniformly distributed
random number \(r\in [0,1]\) and summing the weights of the hypercubes
until the sum exceeds this number. The last hypercube in this sum is
then chosen and one sample is obtained. Taking more than one sample
can improve performance, but introduces bias, as hypercubes with low
weight may be oversampled. At various points, the
\texttt{numba}~\cite{lam2015:po} package has been used to just-in-time
compile code to increase performance. The python
\texttt{multiprocessing} module is used to parallelize the sampling
and exploit all CPU cores. Although the \vegas\ step is very time
intensive, but the actual sampling performance is in the same order of
magnitude as \sherpa, but some parameters have to be manually tuned.

A sample of \result{xs/python/pdf/sample_size} events has been
generated both in \sherpa\ (with the same cuts) and through own
code. The resulting histograms of some observables are depicted in
\cref{fig:pdf-histos}. The sampling efficiency achieved was
\result{xs/python/pdf/samp_eff} using a total of
\result{xs/python/pdf/num_increments} hypercubes.  As can be seen, the
distributions are compatible with each other. The sherpa runcard
utilized here and the analysis used to produce the histograms can be
found in \cref{sec:ppruncard,sec:ppanalysis}. When comparing
\cref{fig:pdf-eta,fig:histeta} it becomes apparent, that the PDF has
substantial influence on the resulting distribution. Also the center
of momentum energy is not constant anymore and has a steep peak at low
energies due to the steepness of the PDF. The convolution with the pdf
has also smoothed out the jacobian peak seen in \cref{fig:histpt}.

Furthermore new observables have been introduced.  The invariant mass
of the photon pair
\(m_{\gamma\gamma} = (p_{\gamma,1} + p_{\gamma,2})^2\) is the center
of mass energy of the partonic system that produces the photons (see
\cref{eq:ecm_partons}) and proportional to the product of the momentum
fractions of the partons. \Cref{fig:pdf-inv-m} shows, that the vast
majority of the reactions take place at a rather low c.m. energy,
owing to the high weights of the PDF at small \(x\) values. Due to the
\(\pt\) cuts the first bin is slightly lower then the second.

The cosines of the scattering angles in the labe frame and the
Collins-Soper (CS) frame are defined in
\cref{eq:sangle,eq:sangle-cs}. The scattering angle is just the angle
between one photon and the z-axis (beam axis) in the c.m. frame if
this frame can be reached by a boost along the z-\footnote{Or me
  generally, in a z-boosted frame where the angles of the two photons
  are the same.}. Here, the partons are assumed to have no transverse
momentum and the system is symmetric around the beam axis and
therefore this boost is possible. When allowing transverse parton
momenta, as will be done in \cref{chap:pheno} this symmetry goes
away. Defining the z-axis as one beam axis in the c.m. frame would be
quite an arbitrary choice that disrespects the symmetry of the two
beams considered here (same energy, identical protons).  Also the
random direction of the transverse momentum can add noise that does
not contain much information. The CS frame is defined as the rest
frame of the two outgoing photons in which the z-axis bisects the
angle between the first beam momentum and the inverse momentum of the
second beam. In this frame, which was originally conceived to simplify
the extension of the Drell-Yan parton model to transverse parton
momenta~\cite{collins:1977an}, some symmetry is restored and the study
of effects of transverse parton momenta is facilitated. Because of the
above-mentioned symmetry, the histograms in
\cref{fig:pdf-o-angle,fig:pdf-o-angle-cs} are the same. One would
naively expect some likeness to \cref{fig:distcos} but the cuts
imposed alter the distribution quite considerably, cutting of the
\(\cos\theta^\ast\rightarrow 1\) region.
% TODO: come back to that in next chapter TODO: graphic (tikz)
%
\begin{align}
  \cos\theta^\ast &= \tanh\frac{\eta_1 - \eta_2}{2} \label{eq:sangle}\\
  \cos\theta^*_\text{CS} &= \frac{\sinh(\eta_1 -
                           \eta_2)}{\sqrt{1+(p_{\text{T},1} + p_{\text{T},2})^2/m_{\gamma\gamma}^2}}\cdot
                          \frac{2p_{\text{T},1}p_{\text{T},2}}{m_{\gamma\gamma}^2}\label{eq:sangle-cs}
\end{align}
%
\begin{figure}[hp]
  \centering
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/eta_hist}
    \caption{\label{fig:pdf-eta} \(\eta\) distribution.}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/pt_hist}
    \caption{\label{fig:pdf-pt} \(\pt\) distribution.}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/cos_theta_hist}
    \caption{\label{fig:pdf-cos-theta} \(\cos\theta\) distribution.}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/inv_m_hist}
    \caption[Histogram of the invariant mass of the final state photon
    system.]{\label{fig:pdf-inv-m} Invariant mass of the
      final state photon system. % This is equal to the center of mass
      % energy of the partonic system before the scattering.
    }
  \end{subfigure}
\end{figure}
%
\begin{figure}
  \ContinuedFloat
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/o_angle_cs_hist}
    \caption{\label{fig:pdf-o-angle-cs} Scattering angle of the two
      photons in the CS frame.}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \centering \plot{pdf/o_angle_hist}
    \caption{\label{fig:pdf-o-angle} Scattering angle of the two
      photons in the lab frame.}
  \end{subfigure}
  \caption{\label{fig:pdf-histos}Comparison of histograms of
    observables for \(\ppgg\) generated manually and by \sherpa/\rivet
    and normalized to unity. The sample size was \protect
    \result{xs/python/pdf/sample_size}. }
\end{figure}
%
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../document"
%%% End:
