#+PROPERTY: header-args :exports both :output-dir results :session xs :kernel python3
#+HTML_HEAD: <link rel="stylesheet" href="tufte.css" />
#+OPTIONS: html-style:nil
#+HTML_CONTAINER: section
#+TITLE: Investigaton of Monte-Carlo Methods
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+NAME: e988e3f2-ad1f-49a3-ad60-bedba3863283
#+begin_src jupyter-python :exports both :tangle tangled/xs.py
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
#+end_src

#+RESULTS: e988e3f2-ad1f-49a3-ad60-bedba3863283

** Utilities
#+NAME: 53548778-a4c1-461a-9b1f-0f401df12b08
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS: 53548778-a4c1-461a-9b1f-0f401df12b08
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload

* Implementation
#+NAME: 777a013b-6c20-44bd-b58b-6a7690c21c0e
#+BEGIN_SRC jupyter-python :exports both :results raw drawer :exports code :tangle tangled/xs.py
  """
  Implementation of the analytical cross section for q q_bar ->
  gamma gamma

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np

  # NOTE: a more elegant solution would be a decorator
  def energy_factor(charge, esp):
      """
      Calculates the factor common to all other values in this module

      Arguments:
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementary charge
      """

      return charge**4/(137.036*esp)**2/6


  def diff_xs(θ, charge, esp):
      """
      Calculates the differential cross section as a function of the
      azimuth angle θ in units of 1/GeV².

      Here dΩ=sinθdθdφ

      Arguments:
      θ -- azimuth angle
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementary charge
      """

      f = energy_factor(charge, esp)
      return f*((np.cos(θ)**2+1)/np.sin(θ)**2)

  def diff_xs_cosθ(cosθ, charge, esp):
      """
      Calculates the differential cross section as a function of the
      cosine of the azimuth angle θ in units of 1/GeV².

      Here dΩ=d(cosθ)dφ

      Arguments:
      cosθ -- cosine of the azimuth angle
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementary charge
      """

      f = energy_factor(charge, esp)
      return f*((cosθ**2+1)/(1-cosθ**2))


  def diff_xs_eta(η, charge, esp):
      """
      Calculates the differential cross section as a function of the
      pseudo rapidity of the photons in units of 1/GeV^2.

      This is actually the crossection dσ/(dφdη).

      Arguments:
      η -- pseudo rapidity
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementary charge
      """

      f = energy_factor(charge, esp)
      return f*(np.tanh(η)**2 + 1)


  def diff_xs_p_t(p_t, charge, esp):
      """
      Calculates the differential cross section as a function of the
      transverse momentum (p_t) of the photons in units of 1/GeV^2.

      This is actually the crossection dσ/(dφdp_t).

      Arguments:
      p_t -- transverse momentum in GeV
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementary charge
      """

      f = energy_factor(charge, esp)
      sqrt_fact = np.sqrt(1-(2*p_t/esp)**2)
      return f/p_t*(1/sqrt_fact + sqrt_fact)


  def total_xs_eta(η, charge, esp):
      """
      Calculates the total cross section as a function of the pseudo
      rapidity of the photons in units of 1/GeV^2.  If the rapditiy is
      specified as a tuple, it is interpreted as an interval.  Otherwise
      the interval [-η, η] will be used.

      Arguments:
      η -- pseudo rapidity (tuple or number)
      esp -- center of momentum energy in GeV
      charge -- charge of the particle in units of the elementar charge
      """

      f = energy_factor(charge, esp)
      if not isinstance(η, tuple):
          η = (-η, η)

      if len(η) != 2:
          raise ValueError('Invalid η cut.')

      def F(x):
          return np.tanh(x) - 2*x

      return 2*np.pi*f*(F(η[0]) - F(η[1]))
#+END_SRC

#+RESULTS: 777a013b-6c20-44bd-b58b-6a7690c21c0e

* Calculations
First, set up the input parameters.
#+BEGIN_SRC jupyter-python :exports both :results raw drawer
η = 2.5
charge = 1/3
esp = 200  # GeV
#+END_SRC

#+RESULTS:

Set up the integration and plot intervals.
#+begin_src jupyter-python :exports both :results raw drawer
interval_η = [-η, η]
interval = η_to_θ([-η, η])
interval_cosθ = np.cos(interval)
interval_pt = np.sort(η_to_pt([0, η], esp/2))
plot_interval = [0.1, np.pi-.1]
#+end_src

#+RESULTS:

#+begin_note
Note that we could utilize the symetry of the integrand throughout,
but that doen't reduce variance and would complicate things now.
#+end_note

** Analytical Integration
 And now calculate the cross section in picobarn.
 #+BEGIN_SRC jupyter-python :exports both :results raw file :file xs.tex
   xs_gev = total_xs_eta(η, charge, esp)
   xs_pb = gev_to_pb(xs_gev)
   tex_value(xs_pb, unit=r'\pico\barn', prefix=r'\sigma = ',
             prec=6, save=('results', 'xs.tex'))
 #+END_SRC

 #+RESULTS:
 : \(\sigma = \SI{0.053793}{\pico\barn}\)

 Lets plot the total xs as a function of η.
 #+begin_src jupyter-python :exports both :results raw drawer
   fig, ax = set_up_plot()
   η_s = np.linspace(0, 3, 1000)
   ax.plot(η_s, gev_to_pb(total_xs_eta(η_s, charge, esp)))
   ax.set_xlabel(r'$\eta$')
   ax.set_ylabel(r'$\sigma$ [pb]')
   ax.set_xlim([0, max(η_s)])
   ax.set_ylim(0)
   save_fig(fig, 'total_xs', 'xs', size=[2.5, 2.5])
 #+end_src

 #+RESULTS:
 [[file:./.ob-jupyter/4522eb3fbeaa14978f9838371acb0650910b8dbf.png]]


 Compared to sherpa, it's pretty close.
 #+NAME: 81b5ed93-0312-45dc-beec-e2ba92e22626
 #+BEGIN_SRC jupyter-python :exports both :results raw drawer
   sherpa = 0.05380
   xs_pb - sherpa
 #+END_SRC

 #+RESULTS: 81b5ed93-0312-45dc-beec-e2ba92e22626
 : -6.7112594623469635e-06

 I had to set the runcard option ~EW_SCHEME: alpha0~ to use the pure
 QED coupling constant.

** Numerical Integration
Plot our nice distribution:
#+begin_src jupyter-python :exports both :results raw drawer
  plot_points = np.linspace(*plot_interval, 1000)

  fig, ax = set_up_plot()
  ax.plot(plot_points, gev_to_pb(diff_xs(plot_points, charge=charge, esp=esp)))
  ax.set_xlabel(r'$\theta$')
  ax.set_ylabel(r'$d\sigma/d\Omega$ [pb]')
  ax.set_xlim([plot_points.min(), plot_points.max()])
  ax.axvline(interval[0], color='gray', linestyle='--')
  ax.axvline(interval[1], color='gray', linestyle='--', label=rf'$|\eta|={η}$')
  ax.legend()
  save_fig(fig, 'diff_xs', 'xs', size=[2.5, 2.5])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3dd905e7608b91a9d89503cb41660152f3b4b55c.png]]

Define the integrand.
#+begin_src jupyter-python :exports both :results raw drawer
  def xs_pb_int(θ):
      return 2*np.pi*gev_to_pb(np.sin(θ)*diff_xs(θ, charge=charge, esp=esp))

  def xs_pb_int_η(η):
      return 2*np.pi*gev_to_pb(diff_xs_eta(η, charge, esp))
#+end_src

#+RESULTS:

Plot the integrand. # TODO: remove duplication
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax.plot(plot_points, xs_pb_int(plot_points))
  ax.set_xlabel(r'$\theta$')
  ax.set_ylabel(r'$2\pi\cdot d\sigma/d\theta [pb]')
  ax.set_xlim([plot_points.min(), plot_points.max()])
  ax.axvline(interval[0], color='gray', linestyle='--')
  ax.axvline(interval[1], color='gray', linestyle='--', label=rf'$|\eta|={η}$')
  save_fig(fig, 'xs_integrand', 'xs', size=[3, 2.2])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ccb6653162c81c3f3e843225cb8d759178f497e0.png]]
*** Integral over θ
Intergrate σ with the mc method.
#+begin_src jupyter-python :exports both :results raw drawer
  xs_pb_res = monte_carlo.integrate(xs_pb_int, interval, epsilon=1e-3)
  xs_pb_res
#+end_src

#+RESULTS:
: IntegrationResult(result=0.05446762390249323, sigma=0.0008255267345438883, N=3062)

We gonna export that as tex.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(*xs_pb_res.combined_result, unit=r'\pico\barn',
            prefix=r'\sigma = ', save=('results', 'xs_mc.tex'))
  tex_value(xs_pb_res.N, prefix=r'N = ', save=('results', 'xs_mc_N.tex'))
#+end_src

#+RESULTS:
: \(N = 3062\)

*** Integration over η
Plot the intgrand of the pseudo rap.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  points = np.linspace(-4, 4, 1000)
  ax.set_xlim([-4, 4])
  ax.plot(points, xs_pb_int_η(points))
  ax.set_xlabel(r'$\eta$')
  ax.set_ylabel(r'$2\pi\cdot d\sigma/d\eta$ [pb]')
  ax.axvline(interval_η[0], color='gray', linestyle='--')
  ax.axvline(interval_η[1], color='gray', linestyle='--', label=rf'$|\eta|={η}$')
  save_fig(fig, 'xs_integrand_eta', 'xs', size=[3, 2])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/87a932866f779a2a07abed4ca251fa98113beca7.png]]

#+begin_src jupyter-python :exports both :results raw drawer
  xs_pb_η = monte_carlo.integrate(xs_pb_int_η,
                                  interval_η, epsilon=1e-3)
  xs_pb_η
#+end_src

#+RESULTS:
: IntegrationResult(result=0.055248826717273894, sigma=0.000850578242116393, N=146)

As we see, the result is a little better if we use pseudo rapidity,
because the differential cross section does not difverge anymore.  But
becase our η interval is covering the range where all the variance is
occuring, the improvement is rather marginal.

And yet again export that as tex.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(*xs_pb_η.combined_result, unit=r'\pico\barn', prefix=r'\sigma = ',
            save=('results', 'xs_mc_eta.tex'))
  tex_value(xs_pb_η.N, prefix=r'N = ', save=('results', 'xs_mc_eta_N.tex'))
#+end_src

#+RESULTS:
: \(N = 146\)

*** Using =VEGAS=
Now we use =VEGAS= on the θ parametrisation and see what happens.
#+begin_src jupyter-python :exports both :results raw drawer
  num_increments = 11
  xs_pb_vegas = monte_carlo.integrate_vegas(
      xs_pb_int,
      interval,
      num_increments=num_increments,
      alpha=1,
      epsilon=1e-3,
      acumulate=False,
      vegas_point_density=100,
  )
  xs_pb_vegas
#+end_src

#+RESULTS:
: VegasIntegrationResult(result=0.05298831377390104, sigma=0.00047316856812983164, N=275, increment_borders=array([0.16380276, 0.26548101, 0.40499559, 0.60444615, 0.89082264,
:        1.30461587, 1.82011605, 2.23778302, 2.52798618, 2.72944603,
:        2.87319285, 2.9777899 ]), vegas_iterations=8)

This is pretty good, although the variance reduction may be achieved
partially by accumulating the results from all runns. Here this gives
us one order of magnitude more than we wanted.

And export that as tex.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(*xs_pb_vegas.combined_result, unit=r'\pico\barn',
            prefix=r'\sigma = ', save=('results', 'xs_mc_θ_vegas.tex'))
  tex_value(xs_pb_vegas.N, prefix=r'N = ', save=('results', 'xs_mc_θ_vegas_N.tex'))
  tex_value(num_increments, prefix=r'K = ', save=('results', 'xs_mc_θ_vegas_K.tex'))
#+end_src

#+RESULTS:
: \(K = 11\)

Surprisingly, acumulation, the result ain't much different.
This depends, of course, on the iteration count.
#+begin_src jupyter-python :exports both :results raw drawer
  monte_carlo.integrate_vegas(
      xs_pb_int,
      interval,
      num_increments=num_increments,
      alpha=1,
      epsilon=1e-3,
      acumulate=True,
      vegas_point_density=100,
  )
#+end_src

#+RESULTS:
: VegasIntegrationResult(result=0.0535800515088519, sigma=0.00040500997978091293, N=275, increment_borders=array([0.16380276, 0.28247078, 0.44038447, 0.65707635, 0.95860989,
:        1.36018749, 1.82461022, 2.21635638, 2.50506504, 2.71436708,
:        2.86527609, 2.9777899 ]), vegas_iterations=6)

Let's define some little helpers.
#+begin_src jupyter-python :exports both :tangle tangled/plot_utils.py
  def plot_increments(ax, increment_borders, label=None, *args, **kwargs):
      """Plot the increment borders from a list.  The first and last one

      :param ax: the axis on which to draw
      :param list increment_borders: the borders of the increments
      :param str label: the label to apply to one of the vertical lines
      """

      ax.axvline(x=increment_borders[1], label=label, *args, **kwargs)

      for increment in increment_borders[1:-1]:
          ax.axvline(x=increment, *args, **kwargs)


  def plot_vegas_weighted_distribution(
      ax, points, dist, increment_borders, *args, **kwargs
  ):
      """Plot the distribution with VEGAS weights applied.

      :param ax: axis
      :param points: points
      :param dist: distribution
      :param increment_borders: increment borders
      """

      num_increments = increment_borders.size
      weighted_dist = dist.copy()

      for left_border, right_border in zip(increment_borders[:-1], increment_borders[1:]):
          length = right_border - left_border
          mask = (left_border <= points) & (points <= right_border)
          weighted_dist[mask] = dist[mask] * num_increments * length

      ax.plot(points, weighted_dist, *args, **kwargs)


  def plot_stratified_rho(ax, points, increment_borders, *args, **kwargs):
      """Plot the weighting distribution resulting from the increment
      borders.

      :param ax: axis
      :param points: points
      :param increment_borders: increment borders

      """

      num_increments = increment_borders.size
      ρ = np.empty_like(points)
      for left_border, right_border in zip(increment_borders[:-1], increment_borders[1:]):
          length = right_border - left_border
          mask = (left_border <= points) & (points <= right_border)
          ρ[mask] = 1 / (num_increments * length)

      ax.plot(points, ρ, *args, **kwargs)
#+end_src

#+RESULTS:

And now we plot the integrand with the incremens.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax.set_xlim(*interval)
  ax.set_xlabel(r"$\theta$")
  ax.set_ylabel(r"$2\pi\cdot d\sigma/d\theta$ [pb]")
  ax.set_ylim([0, 0.09])

  ax.plot(plot_points, xs_pb_int(plot_points), label="Distribution")

  plot_increments(
      ax,
      xs_pb_vegas.increment_borders,
      label="Increment Borders",
      color="gray",
      linestyle="--",
  )

  plot_vegas_weighted_distribution(
      ax,
      plot_points,
      xs_pb_int(plot_points),
      xs_pb_vegas.increment_borders,
      label="Weighted Distribution",
  )

  ax.legend(fontsize="small", loc="lower left")
  save_fig(fig, "xs_integrand_vegas", "xs", size=[5, 3])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/758cf975863edaae1cd9d3b4683ce494e736ddb7.png]]
*** Testing the Statistics
Let's battle test the statistics.
#+begin_src jupyter-python :exports both :results raw drawer
  num_runs = 1000
  num_within = 0

  for _ in range(num_runs):
      val, err = \
          monte_carlo.integrate(xs_pb_int, interval, epsilon=1e-3).combined_result
      if abs(xs_pb - val) <= err:
          num_within += 1

  num_within/num_runs
#+end_src

#+RESULTS:
: 0.665

So we see: the standard deviation is sound.

Doing the same thing with =VEGAS= works as well.
#+begin_src jupyter-python :exports both :results raw drawer
  num_runs = 1000
  num_within = 0
  for _ in range(num_runs):
      val, err = \
          monte_carlo.integrate_vegas(xs_pb_int, interval,
                                      num_increments=10, alpha=1,
                                      epsilon=1e-3, acumulate=False,
                                      vegas_point_density=100).combined_result

      if abs(xs_pb - val) <= err:
          num_within += 1
  num_within/num_runs
#+end_src

#+RESULTS:
: 0.691

** Sampling and Analysis
Define the sample number.
#+begin_src jupyter-python :exports both :results raw drawer
  sample_num = 10000
  tex_value(
      sample_num, prefix="N = ", save=("results", "4imp-sample-size.tex"),
  )
#+end_src

#+RESULTS:
: \(N = 10000\)

Let's define shortcuts for our distributions. The 2π are just there
for formal correctnes. Factors do not influecence the outcome.
#+begin_src jupyter-python :exports both :results raw drawer
  def dist_cosθ(x):
      return gev_to_pb(diff_xs_cosθ(x, charge, esp))

  def dist_η(x):
      return gev_to_pb(diff_xs_eta(x, charge, esp))
#+end_src

#+RESULTS:

*** Sampling the cosθ cross section

Now we monte-carlo sample our distribution. We observe that the efficiency his very bad!
#+begin_src jupyter-python :exports both :results raw drawer
  cosθ_sample, cosθ_efficiency = \
      monte_carlo.sample_unweighted_array(sample_num, dist_cosθ,
                                          interval_cosθ, report_efficiency=True)
  cosθ_efficiency
#+end_src

#+RESULTS:
: 0.027528608061949504

Let's save that.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(
      cosθ_efficiency * 100,
      prefix=r"\mathfrak{e} = ",
      suffix=r"\%",
      save=("results", "naive_th_samp.tex"),
  )
#+end_src

#+RESULTS:
: \(\mathfrak{e} = 3\%\)

Our distribution has a lot of variance, as can be seen by plotting it.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.linspace(*interval_cosθ, 100)
  fig, ax = set_up_plot()
  ax.plot(pts, dist_cosθ(pts))
  ax.set_xlabel(r'$\cos\theta$')
  ax.set_ylabel(r'$\frac{d\sigma}{d\Omega}$')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, '$\\frac{d\\sigma}{d\\Omega}$')
[[file:./.ob-jupyter/a9e1c809c0f72c09ab5e91022ecd407fcc833d95.png]]
:END:

We define a friendly and easy to integrate upper limit function.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  upper_limit = dist_cosθ(interval_cosθ[0]) / interval_cosθ[0] ** 2
  upper_base = dist_cosθ(0)


  def upper(x):
      return upper_base + upper_limit * x ** 2


  def upper_int(x):
      return upper_base * x + upper_limit * x ** 3 / 3


  ax.plot(pts, upper(pts), label="upper bound")
  ax.plot(pts, dist_cosθ(pts), label=r"$f_{\cos\theta}$")

  ax.legend(fontsize='small')
  ax.set_xlabel(r"$\cos\theta$")
  ax.set_ylabel(r"$\frac{d\sigma}{d\cos\theta}$ [pb]")
  save_fig(fig, "upper_bound", "xs_sampling", size=(3, 2.5))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/647593b36e5170280820c31c63b884cae0ebbee6.png]]


To increase our efficiency, we have to specify an upper bound. That is
at least a little bit better. The numeric inversion is horribly inefficent.
#+begin_src jupyter-python :exports both :results raw drawer
  cosθ_sample_tuned, cosθ_efficiency_tuned = \
      monte_carlo.sample_unweighted_array(sample_num, dist_cosθ,
                                          interval_cosθ, report_efficiency=True,
                                          upper_bound=[upper, upper_int])
  cosθ_efficiency_tuned
#+end_src

#+RESULTS:
: 0.07922836784545058
<<cosθ-bare-eff>>

#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(
      cosθ_efficiency_tuned * 100,
      prefix=r"\mathfrak{e} = ",
      suffix=r"\%",
      save=("results", "tuned_th_samp.tex"),
  )
#+end_src

#+RESULTS:
: \(\mathfrak{e} = 8\%\)

# TODO: Looks fishy
Nice! And now draw some histograms.

We define an auxilliary method for convenience.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/plot_utils.py
  """
  Some shorthands for common plotting tasks related to the investigation
  of monte-carlo methods in one rimension.

  Author: Valentin Boettcher <hiro at protagon.space>
  """

  import matplotlib.pyplot as plt


  def draw_histo(points, xlabel, bins=50):
      heights, edges = np.histogram(points, bins)
      centers = (edges[1:] + edges[:-1]) / 2
      deviations = np.sqrt(heights)
      integral = heights @ (edges[1:] - edges[:-1])
      heights = heights/integral
      deviations = deviations/integral

      fig, ax = set_up_plot()
      ax.errorbar(centers, heights, deviations, linestyle="none", color="orange")
      ax.step(edges, [heights[0], *heights], color="#1f77b4")

      ax.set_xlabel(xlabel)
      ax.set_ylabel("Count")
      ax.set_xlim([points.min(), points.max()])
      return fig, ax
#+end_src

#+RESULTS:

The histogram for cosθ.
#+begin_src jupyter-python :exports both :results raw drawer
fig, _ = draw_histo(cosθ_sample, r'$\cos\theta$')
save_fig(fig, 'histo_cos_theta', 'xs', size=(4,3))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f900cd1f2938395ee04417e0c8369c23d883622c.png]]

*** Observables
Now we define some utilities to draw real 4-momentum samples.
#+begin_src jupyter-python :exports both :tangle tangled/xs.py
  def sample_momenta(sample_num, interval, charge, esp, seed=None):
      """Samples `sample_num` unweighted photon 4-momenta from the
      cross-section.

      :param sample_num: number of samples to take
      :param interval: cosθ interval to sample from
      :param charge: the charge of the quark
      :param esp: center of mass energy
      :param seed: the seed for the rng, optional, default is system
          time

      :returns: an array of 4 photon momenta

      :rtype: np.ndarray
      """
      cosθ_sample = \
          monte_carlo.sample_unweighted_array(sample_num,
                                              lambda x:
                                                diff_xs_cosθ(x, charge, esp),
                                             interval_cosθ)
      φ_sample = np.random.uniform(0, 1, sample_num)

      def make_momentum(esp, cosθ, φ):
          sinθ = np.sqrt(1-cosθ**2)
          return np.array([1, sinθ*np.cos(φ), sinθ*np.sin(φ), cosθ])*esp/2

      momenta = np.array([make_momentum(esp, cosθ, φ) \
                           for cosθ, φ in np.array([cosθ_sample, φ_sample]).T])
      return momenta
#+end_src

#+RESULTS:

To generate histograms of other obeservables, we have to define them
as functions on 4-impuleses. Using those to transform samples is
analogous to transforming the distribution itself.
#+begin_src jupyter-python :session obs :exports both :results raw drawer :tangle tangled/observables.py
  """This module defines some observables on arrays of 4-pulses."""
  import numpy as np

  def p_t(p):
      """Transverse momentum

      :param p: array of 4-momenta
      """

      return np.linalg.norm(p[:,1:3], axis=1)

  def η(p):
      """Pseudo rapidity.

      :param p: array of 4-momenta
      """

      return np.arccosh(np.linalg.norm(p[:,1:], axis=1)/p_t(p))*np.sign(p[:, 3])
#+end_src

#+RESULTS:

And import them.
#+begin_src jupyter-python :exports both :results raw drawer
  %aimport tangled.observables
  obs = tangled.observables
#+end_src

#+RESULTS:

Lets try it out.
#+begin_src jupyter-python :exports both :results raw drawer
  momentum_sample = sample_momenta(sample_num, interval_cosθ, charge, esp)
  momentum_sample
#+end_src

#+RESULTS:
: array([[100.        ,  81.88196716,  43.22434263, -37.77564902],
:        [100.        ,  24.77634994,  23.19908007,  94.06346351],
:        [100.        ,  89.63521528,  37.54354171, -23.57987825],
:        ...,
:        [100.        ,  21.790537  ,  11.38406619, -96.93077702],
:        [100.        ,  48.21722876,  20.13959487, -85.26133689],
:        [100.        ,  25.93488982,   1.49987455, -96.56672236]])


Now let's make a histogram of the η distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  η_sample = obs.η(momentum_sample)
  fig, ax = draw_histo(η_sample, r'$\eta$')
  save_fig(fig, 'histo_eta', 'xs_sampling', size=[3, 3])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/48d534ff204e6aa5636746b1fccef3658ca24720.png]]


And the same for the p_t (transverse momentum) distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  p_t_sample = obs.p_t(momentum_sample)
  fig, ax = draw_histo(p_t_sample, r"$p_T$ [GeV]")
  save_fig(fig, "histo_pt", "xs_sampling", size=[3, 3])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/4634a469d94a5a88eecf2d1f00068180fe285bbb.png]]

That looks somewhat fishy, but it isn't.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  points = np.linspace(interval_pt[0], interval_pt[1] - .01, 1000)
  ax.plot(points, gev_to_pb(diff_xs_p_t(points, charge, esp)))
  ax.set_xlabel(r'$p_T$')
  ax.set_xlim(interval_pt[0], interval_pt[1] + 1)
  ax.set_ylim([0, gev_to_pb(diff_xs_p_t(interval_pt[1] -.01, charge, esp))])
  ax.set_ylabel(r'$\frac{d\sigma}{dp_t}$ [pb]')
  save_fig(fig, 'diff_xs_p_t', 'xs_sampling', size=[4, 2])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/29724b8c1f2b0005a05f64f999cf95d248ee0082.png]]
this is strongly peaked at p_t=100GeV. (The jacobian goes like 1/x there!)

*** Sampling the η cross section
An again we see that the efficiency is way, way! better...
#+begin_src jupyter-python :exports both :results raw drawer
  η_sample, η_efficiency = monte_carlo.sample_unweighted_array(
      sample_num, dist_η, interval_η, report_efficiency=True
  )
  tex_value(
      η_efficiency * 100,
      prefix=r"\mathfrak{e} = ",
      suffix=r"\%",
      save=("results", "eta_eff.tex"),
  )
#+end_src

#+RESULTS:
: \(\mathfrak{e} = 41\%\)
<<η-eff>>

Let's draw a histogram to compare with the previous results.
#+begin_src jupyter-python :exports both :results raw drawer
  draw_histo(η_sample, r'$\eta$')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example

  TypeErrorTraceback (most recent call last)
  <ipython-input-152-135da139cc01> in <module>
  ----> 1 draw_histo(η_sample, r'$\eta$')

  <ipython-input-143-0369283d77d0> in draw_histo(points, xlabel, bins)
       14     deviations = np.sqrt(heights)
       15     integral = heights @ (edges[1:] - edges[:-1])
  ---> 16     heights /= integral
       17     deviations /= integral
       18

  TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''
#+end_example
:END:


Looks good to me :).

*** Sampling with =VEGAS=
To get the increments, we have to let =VEGAS= loose on our
distribution. We throw away the integral, but keep the increments.

#+begin_src jupyter-python :exports both :results raw drawer
  K = 10
  increments = monte_carlo.integrate_vegas(
      dist_cosθ, interval_cosθ, num_increments=K, alpha=1, increment_epsilon=0.001
  ).increment_borders
  tex_value(
      K, prefix=r"K = ", save=("results", "vegas_samp_num_increments.tex"),
  )
  increments
#+end_src

#+RESULTS:
: array([-0.9866143 , -0.9696821 , -0.93140574, -0.84140036, -0.60391287,
:        -0.0080662 ,  0.59861242,  0.83680834,  0.93037032,  0.96942902,
:         0.9866143 ])

Visualizing the increment borders gives us the information we want.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.linspace(*interval_cosθ, 100)
  fig, ax = set_up_plot()
  ax.plot(pts, dist_cosθ(pts))
  ax.set_xlabel(r'$\cos\theta$')
  ax.set_ylabel(r'$\frac{d\sigma}{d\Omega}$')
  ax.set_xlim(*interval_cosθ)
  plot_increments(ax, increments,
                  label='Increment Borderds', color='gray', linestyle='--')
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fb32e85b6d0>
[[file:./.ob-jupyter/225f173c081af4bd603b1f1c8a148ad3c6950364.png]]
:END:

We can now plot the reweighted distribution to observe the variance
reduction visually.

#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.linspace(*interval_cosθ, 1000)
  fig, ax = set_up_plot()
  ax.plot(pts, dist_cosθ(pts), label="Distribution")
  plot_vegas_weighted_distribution(
      ax, pts, dist_cosθ(pts), increments, label="Weighted Distribution"
  )
  ax.set_xlabel(r"$\cos\theta$")
  ax.set_ylabel(r"$\frac{d\sigma}{d\cos\theta}$")
  ax.set_xlim(*interval_cosθ)
  plot_increments(
      ax, increments, label="Increment Borderds", color="gray", linestyle="--"
  )
  ax.legend(fontsize="small")
  save_fig(fig, "vegas_strat_dist", "xs_sampling", size=(3, 2.3))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3627649a346f32e23d7dc55f4f54ead6f7c8c631.png]]


I am batman! Let's plot the weighting distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.linspace(*interval_cosθ, 1000)
  fig, ax = set_up_plot()
  plot_stratified_rho(ax, pts, increments)
  ax.set_xlabel(r"$\cos\theta$")
  ax.set_ylabel(r"$\rho")
  ax.set_xlim(*interval_cosθ)
  save_fig(fig, "vegas_rho", "xs_sampling", size=(3, 2.3))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/535b557096180f27688951eedf76fc9347051519.png]]

Now, draw a sample and look at the efficiency.

#+begin_src jupyter-python :exports both :results raw drawer
  cosθ_sample_strat, cosθ_efficiency_strat = \
      monte_carlo.sample_unweighted_array(sample_num, dist_cosθ,
                                          increment_borders=increments,
                                          report_efficiency=True)
  cosθ_efficiency_strat
#+end_src

#+RESULTS:
: 0.57751

#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(
      cosθ_efficiency_strat * 100,
      prefix=r"\mathfrak{e} = ",
      suffix=r"\%",
      save=("results", "strat_th_samp.tex"),
  )
#+end_src

#+RESULTS:
: \(\mathfrak{e} = 58\%\)

If we compare that to [[cosθ-bare-eff]], we can see the improvement :P.
It is even better the [[η-eff]].  The histogram looks just the same.

#+begin_src jupyter-python :exports both :results raw drawer
fig, _ = draw_histo(cosθ_sample_strat, r'$\cos\theta$')
save_fig(fig, 'histo_cos_theta_strat', 'xs', size=(4,3))
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/a897f7c69f8ce079d652c731b2097849480a8a50.png]]
*** Some Histograms with Rivet
**** Init
#+begin_src jupyter-python :exports both :results raw drawer
  import yoda
#+end_src

#+RESULTS:

**** Plot the Histos
#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/plot_utils.py
  def draw_yoda_histo(h, xlabel):
      edges = np.append(h.xMins(), h.xMax())
      heights = np.append(h.yVals(), h.yVals()[-1])
      centers = (edges[1:] + edges[:-1]) / 2

      fig, ax = set_up_plot()
      ax.errorbar(h.xVals(), h.yVals(), h.yErrs(), linestyle="none", color="orange")
      ax.step(edges, heights, color="#1f77b4", where="post")

      ax.set_xlabel(xlabel)
      ax.set_ylabel("Count")
      ax.set_xlim([h.xMin(), h.xMax()])
      return fig, ax
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/qqgg/analysis/Analysis.yoda")
  sherpa_histos = {"pT": r"$p_T$", "eta": r"$\eta$", "cos_theta": r"$\cos\theta$"}

  for key, label in sherpa_histos.items():
      fig, _ = draw_yoda_histo(yoda_file["/MC_DIPHOTON_SIMPLE/" + key], r"Sherpa " + label)
      save_fig(fig, "histo_sherpa_" + key, "xs_sampling", size=(3, 3))
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/e779e9e8081ac63faee9de5e332bb0ef2721b10d.png]]
[[file:./.ob-jupyter/1daef5b1773483e0e176cac4a738f1c671c7becb.png]]
[[file:./.ob-jupyter/a1bf8dec2faba69b35d48499c06ada0588ae713b.png]]
:END:
