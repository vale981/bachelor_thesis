#+PROPERTY: header-args :exports both :output-dir results :kernel python3 :session :session pdf
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
  import lhapdf
#+end_src

#+RESULTS:
: Welcome to JupyROOT 6.20/04

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%aimport tangled
from tangled import observables
%autoreload 1
#+END_SRC

#+RESULTS:

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
  η = 2.5
  min_pT = 20
  e_proton = 6500  # GeV
  interval_η = [-η, η]
  interval = η_to_θ([-η, η])
  interval_cosθ = [-1, 1]
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

We gonna export that for reference in the tex document.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(min_pT, prefix=r"\pt \geq ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "min_pT.tex"))
  tex_value(e_proton, prefix=r"E_p = ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "e_proton.tex"))
  tex_value(η, prefix=r"\abs{\eta} \leq ", prec=0, save=("results/pdf/", "eta.tex"))
#+end_src


#+RESULTS:
: \(\abs{\eta} \leq 2\)

* Implementation
** Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64, boolean
  import lab_xs.lab_xs as c_xs


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  class Cut:
      def __init__(self):
          self._other = None
          self._current_comb = self._call

          self._greater_than = 0
          self._lower_than = np.inf

      def __gt__(self, greater_than):
          self._greater_than = greater_than

          return self

      def __lt__(self, lower_than):
          self._lower_than = lower_than

          return self

      def _or_comb(self, event):
          return self._call(event) or self._other(event)

      def _and_comb(self, event):
          return self._call(event) and self._other(event)

      def _call(self, event):
          return self._greater_than < self._calculate(event) < self._lower_than

      def _calculate(self, event):
          raise NotImplementedError('"_calulate" must be implemented.')

      def __call__(self, event):
          return self._current_comb(event)

      def __and__(self, other):
          self._other = other
          self._current_comb = self._and_comb

          return self

      def __or__(self, other):
          self._other = other
          self._current_comb = self._or_comb

          return self

      def apply(self, function):
          @wraps(function)
          def wrapper(event):
              if self(event):
                  return function(event)

              return 0

          return wrapper


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2


  class CutpT(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          e_hadron, eta, x_1, x_2 = event
          return c_xs.pT(e_hadron, eta, x_1, x_2)


  class CutOtherEta(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          _, η, x_1, x_2 = event
          return c_xs.second_eta(η, x_1, x_2)
#+end_src

#+RESULTS:

** Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(
                      q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2
                  )
                  / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs,
      q,
      e_hadron,
      quarks=None,
      pdf=None,
      cut=None,
      num_points_pdf=1000,
      vectorize=False,
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = (
          quarks
          if quarks is not None
          else np.array([[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]])
      )  # all the light quarks

      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      def distribution(angle_arg, x_1, x_2) -> float:
          if cut and not cut([e_hadron, angle_arg, x_1, x_2]):
              return 0

          q2_value = q(e_hadron, x_1, x_2)

          xs_value = xs(e_hadron, 1 / 3, angle_arg, x_1, x_2)
          pdf_values = (
              xfxQ2(quarks[:, 0], x_1, q2_value),
              xfxQ2(-quarks[:, 0], x_1, q2_value),
              xfxQ2(quarks[:, 0], x_2, q2_value),
              xfxQ2(-quarks[:, 0], x_2, q2_value),
          )

          result = 0
          xs_value = xs(e_hadron, 1, angle_arg, x_1, x_2)

          for (quark, charge), q_1, qb_1, q_2, qb_2 in zip(quarks, *pdf_values):

              result += ((q_1 * qb_2) + (qb_1 * q_2)) * (charge ** 4)

          return result * xs_value / (x_1 * x_2)  # identical protons

      def vectorized(angle_arg, x_1, x_2):
          results = np.empty_like(angle_arg)
          for a, x__1, x__2, i in zip(angle_arg, x_1, x_2, range(len(results))):
              results[i] = distribution(a, x__1, x__2)
          return results

      return vectorized if vectorize else distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:

* Checking out the partonic xs.
Let's set up a cut for the η of the other photon and codify our
distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  cut_part = (CutpT() > 2000) & (-2.5 < CutOtherEta() < 2.5)


  def part_dist(eta):
      if isinstance(eta, np.ndarray):
          return np.array([part_dist(s_η) for s_η in eta])

      if not cut_part([e_proton, eta, 0.5, 1]) :
          return 0

      return 2 * np.pi * c_xs.diff_xs_eta(e_proton, -1 / 3, eta, 0.5, 1)
#+end_src

#+RESULTS:

The total cross section is as follows:
#+begin_src jupyter-python :exports both :results raw drawer
  part_xs = monte_carlo.integrate(part_dist, [-2.5, 2.5], epsilon=1e-16)
  part_xs
#+end_src

#+RESULTS:
: IntegrationResult(result=3.329425346813745e-14, sigma=9.607139391797041e-17, N=91765)


We have to convert that to picobarn.
#+begin_src jupyter-python :exports both :results raw drawer
  gev_to_pb(part_xs.result), gev_to_pb(part_xs.sigma)
#+end_src

#+RESULTS:
| 1.2964095512354117e-05 | 3.740821904745473e-08 |

That is compatible with sherpa!
#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part, sherpa_part_σ = np.loadtxt('../../runcards/pp_partonic/sherpa_xs')
  sherpa_part, sherpa_part_σ  # GeV
#+end_src

#+RESULTS:
| 1.29935e-05 | 4.71171e-10 |


We can take some samples as well.
#+begin_src jupyter-python :exports both :results raw drawer
  part_samples = monte_carlo.sample_unweighted_array(
      1000000,
      part_dist,
      interval=[-2.5, 2.5],
      proc="auto",
  )
  part_samples.min()
#+end_src

#+RESULTS:
: -1.8206975090375266

#+begin_src jupyter-python :exports both :results raw drawer
part_hist = np.histogram(part_samples, bins=50, range=[-2.5, 2.5])
fig, ax = set_up_plot()
draw_histogram(ax, part_hist)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f912a30cf70>
[[file:./.ob-jupyter/7c8509f0cba9bded6b3413c025c0e3b51d0d678d.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_sherpa_part = yoda.read("../../runcards/pp_partonic/analysis/Analysis.yoda")
  sherpa_part_hist = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/eta"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$\eta$")
  xs = np.linspace(-2.5, 2.5, 1000)
  ax.plot(xs, part_dist(xs)/part_xs.result, label="Distribution")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f912a311b20>
[[file:./.ob-jupyter/83a3de13c780aa2d6395edc0e851b8600d41e21c.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
  part_momenta = momenta(
      e_proton,
      0.5 * np.ones_like(part_samples),
      1 * np.ones_like(part_samples),
      np.tanh(part_samples),
  )
  part_pt = np.sqrt(part_momenta[2][:,2]**2)
  part_pt_hist = np.histogram(part_pt, bins=50, range=(2000, e_proton))
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part_hist_pT = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist_pT, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_pt_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$p_T$")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f912a535760>
[[file:./.ob-jupyter/b715f27c6f2c63ff809fe9e13a697a3d8a01148e.png]]
:END:

* Total XS
Now, it would be interesting to know the total cross section.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η_vec, _ = get_xs_distribution_with_pdf(
        c_xs.diff_xs_eta,
        c_xs.averaged_tchanel_q2,
        e_proton,
        cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
        vectorize=True,
        pdf=pdf,
    )

  xs_int_res = monte_carlo.integrate_vegas_nd(
      dist_η_vec,
      [interval_η, [pdf.xMin, 1], [pdf.xMin, 1]],
      epsilon=1e-11,
      proc=1,
      increment_epsilon=1e-2,
      alpha=1.8,
      num_increments=[3, 100, 100],
      num_points_per_cube=10,
      cache="cache/pdf/total_xs_2_5_20_take19",
  )

  total_xs = gev_to_pb(np.array(xs_int_res.combined_result)) * 2 * np.pi
  total_xs
#+end_src

#+RESULTS:
:RESULTS:
: Loading Cache:  integrate_vegas_nd
: array([3.86636603e+01, 2.05680570e-02])
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa, sherpa_σ = np.loadtxt("../../runcards/pp/sherpa_xs")
  sherpa, sherpa_σ  # GeV
#+end_src

#+RESULTS:
| 38.7275 | 0.0280886 |

A factor of two used to be in here. It stemmed from the fact, that
there are two identical protons.

#+begin_src jupyter-python :exports both :results raw drawer
  abs(sherpa-total_xs[0]) - total_xs[1]
#+end_src

#+RESULTS:
: 0.04327163497143981

The efficiency will be around:
#+begin_src jupyter-python :exports both :results raw drawer
  monte_carlo.estimate_stratified_efficiency(xs_int_res.cubes)
#+end_src

#+RESULTS:
: 34.55338145802887

Let's export those results for TeX:
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(
      ,*xs_int_res.combined_result,
      prefix=r"\sigma = ",
      save=("results/pdf/", "my_sigma.tex"),
      unit=r"\pico\barn"
  )
  tex_value(
      sherpa,
      sherpa_σ,
      prefix=r"\sigma_s = ",
      save=("results/pdf/", "sherpa_sigma.tex"),
      unit=r"\pico\barn",
  )
#+end_src

#+RESULTS:
: \(\sigma_s = \SI{38.728\pm 0.028}{\pico\barn}\)

* Event generation
We set up a new distribution. Look at that cut sugar!
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
      pdf=pdf,
  )

  dist_η_no_cut, _ = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      pdf=pdf,
  )
#+end_src

#+RESULTS:

Now we create an eye-candy surface plot.
#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1, 100)
  ηs = np.linspace(-2.5, 2.5, 100)
  x_2_const = 0.01

  grid_xs, grid_ηs = np.meshgrid(xs, ηs)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut(grid_ηs[i, j], grid_xs[i, j], x_2_const))
              for i in range(len(ηs))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$\eta$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(grid_xs, grid_ηs, pdf_surface, cmap=cm.coolwarm, linewidth=0)
  #fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_x2_const", "pdf", size=(6, 3.5))
  tex_value(x_2_const, prefix=r"x_2 = ", prec=2, save=("results/pdf/", "second_x.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(x_2 = 0.01\)
[[file:./.ob-jupyter/435569ac2b915994a9dda2c14beba363c821370a.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1/4, 100)
  x_2s = np.linspace(0.01, 0.1/4, 100)
  eta_const = 2.5

  grid_xs, grid_x_2s = np.meshgrid(xs, x_2s)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut(eta_const, grid_xs[i, j], grid_x_2s[i, j]))
              for i in range(len(x_2s))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$x_2$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(
      grid_xs, grid_x_2s, pdf_surface, cmap=cm.coolwarm, linewidth=0
  )
  ax.view_init(30, 20)
  ax.xaxis.set_major_locator(plt.MaxNLocator(5))
  ax.yaxis.set_major_locator(plt.MaxNLocator(5))
  # fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_eta_const", "pdf", size=(6, 3.5))
  tex_value(eta_const, prefix=r"\eta = ", prec=2, save=("results/pdf/", "plot_eta.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(\eta = 2.50\)
[[file:./.ob-jupyter/8bf84cb0460b2d5eb083e20c9fa656723585a030.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.logspace(-4, 0, 10000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(2, pt, 2*100**2)/pt for pt in pts])
  ax.set_yscale('log')
  ax.set_xscale('log')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7fe9d3bd60427cf20af835649efbcbaafefbb3e0.png]]


Overestimating the upper bounds helps with bias.
#+begin_src jupyter-python :exports both :results raw drawer
  overestimate = 1.1
  tex_value(
      (overestimate - 1) * 100,
      unit=r"\percent",
      prec=0,
      save=("results/pdf/", "overesimate.tex"),
  )
#+end_src

#+RESULTS:
: \(\SI{10}{\percent}\)

Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  result, eff = monte_carlo.sample_unweighted_array(
      10000_000,
      dist_η,
      cubes=xs_int_res.cubes,
      proc="auto",
      report_efficiency=True,
      cache="cache/pdf/total_xs_10000_000_2_5_take6",
      status_path="/tmp/status1",
      overestimate_factor=overestimate,
  )
  eff
#+end_src

#+RESULTS:
:RESULTS:
: Loading Cache:  sample_unweighted_array
: 0.30393438761119607
:END:

That does look pretty good eh? So lets save it along with the sample size.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(len(result), prefix=r"N=", prec=0, save=("results/pdf/", "sample_size.tex"))
  tex_value(
      (eff) * 100,
      prefix=r"\mathfrak{e}=",
      unit=r"\percent",
      prec=0,
      save=("results/pdf/", "samp_eff.tex"),
  )
#+end_src

#+RESULTS:
: \(\mathfrak{e}=\SI{30}{\percent}\)

** Observables
Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins="auto")
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 10000000
[[file:./.ob-jupyter/4fdcf3895a4c50ebc772054351beb7a07022f64c.png]]
:END:

Let's use a uniform histogram image size.
#+begin_src jupyter-python :exports both :results raw drawer
  hist_size=(3, 3)
#+end_src

#+RESULTS:

And now we compare all the observables with sherpa.
#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist, hist_kwargs=dict(label="Sherpa")),
          dict(
              hist=np.histogram(result[:, 0], bins=50, range=interval_η),
              hist_kwargs=dict(label="own implementation"),
          ),
      ]
  )
  ax_ratio.set_xlabel(r"$\eta$")
  ax.legend()
  save_fig(fig, "eta_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ce5b3690f34e7b274e848668485946023b95658c.png]]

Hah! there we have it!

#+begin_src jupyter-python :exports both :results raw drawer
  mom = momenta(e_proton, result[:,1], result[:,2], np.tanh(result[:,0]))
#+end_src

#+RESULTS:

pT drops pretty quickly.
#+begin_src jupyter-python :exports both :results raw drawer
  pT_hist = np.histogram(observables.p_t(mom[3]), bins=50, range=(min_pT, e_proton))
  yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_pt, hist_kwargs=dict(label="sherpa")),
          dict(hist=pT_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax.set_yscale("log")
  ax.set_xscale("log")
  ax_ratio.set_xlabel(r"$p_T$ [GeV]")
  ax.legend()
  save_fig(fig, "pt_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ec1b57b6284e95a1464ebba2e2930c5ba71427a3.png]]

The invariant mass is not constant anymore.
#+begin_src jupyter-python :exports both :results raw drawer
  inv_m_hist = np.histogram(
  observables.inv_m(mom[2], mom[3]), bins=50, range=(2 * min_pT, 2 * e_proton)
  )
  yoda_hist_inv_m = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/inv_m"])

  # yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_inv_m, hist_kwargs=dict(label="sherpa")),
          dict(hist=inv_m_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax.set_yscale("log")
  ax.set_xscale("log")
  ax_ratio.set_xlabel(r"Invariant Mass [GeV]")
  ax.legend()
  save_fig(fig, "inv_m_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/86b1b2e23482e9faffa688c47d29463de817d2ae.png]]

The cosθ distribution looks more like the paronic one.
#+begin_src jupyter-python :exports both :results raw drawer
  cosθ_hist = np.histogram(
      observables.cosθ(mom[2]), bins=50, range=interval_cosθ
  )
  yoda_hist_cosθ = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/cos_theta"])

  # yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_cosθ, hist_kwargs=dict(label="sherpa")),
          dict(hist=cosθ_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax_ratio.set_xlabel(r"$\cos\theta$")
  ax.legend()
  save_fig(fig, "cos_theta_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/cff558aae0351a7c234c8acc716cd1702faca1d8.png]]
