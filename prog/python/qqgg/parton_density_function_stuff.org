#+PROPERTY: header-args :exports both :output-dir results :session pdf :kernel python3
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
  import lhapdf
#+end_src

#+RESULTS:

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
  η = 1
  min_pT = 200
  e_proton = 6500  # GeV
  interval_η = [-η, η]
  interval = η_to_θ([-η, η])
  interval_cosθ = np.cos(interval)
  num_samples = 10_000
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

* Implementation
** Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64, boolean
  import lab_xs.lab_xs as c_xs


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  class Cut:
      def __init__(self):
          self._other = None
          self._current_comb = self._call

          self._greater_than = 0
          self._lower_than = np.inf

      def __gt__(self, greater_than):
          self._greater_than = greater_than

          return self

      def __lt__(self, lower_than):
          self._lower_than = lower_than

          return self

      def _or_comb(self, event):
          return self._call(event) or self._other(event)

      def _and_comb(self, event):
          return self._call(event) and self._other(event)

      def _call(self, event):
          return self._greater_than < self._calculate(event) < self._lower_than

      def _calculate(self, event):
          raise NotImplementedError('"_calulate" must be implemented.')

      def __call__(self, event):
          return self._current_comb(event)

      def __and__(self, other):
          self._other = other
          self._current_comb = self._and_comb

          return self

      def __or__(self, other):
          self._other = other
          self._current_comb = self._or_comb

          return self

      def apply(self, function):
          @wraps(function)
          def wrapper(event):
              if self(event):
                  return function(event)

              return 0

          return wrapper


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2


  class CutpT(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          e_hadron, eta, x_1, x_2 = event
          return c_xs.pT(e_hadron, eta, x_1, x_2)


  class CutOtherEta(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          _, η, x_1, x_2 = event
          return c_xs.second_eta(η, x_1, x_2)
#+end_src

#+RESULTS:

** Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(
                      q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2
                  )
                  / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs,
      q,
      e_hadron,
      quarks=None,
      pdf=None,
      cut=None,
      num_points_pdf=1000,
      vectorize=False,
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = (
          quarks
          if quarks is not None
          else np.array(
              # [[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]]
              [[1, -1 / 3]]
          )
      )  # all the light quarks

      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      def distribution(event: np.ndarray) -> float:
          if cut and not cut([e_hadron, *event]):
              return 0

          angle_arg, x_1, x_2 = event

          q2_value = q(e_hadron, x_1, x_2)
          result = 0

          for quark, charge in quarks:
              xs_value = xs(e_hadron, charge, angle_arg, x_1, x_2)

              result += (
                  (xfxQ2(quark, x_1, q2_value) + xfxQ2(-quark, x_1, q2_value))
                  / x_1
                  ,* (xfxQ2(-quark, x_2, q2_value) + xfxQ2(quark, x_2, q2_value))
                  / x_2
                  ,* xs_value
              )

          return result

      def vectorized(events):
          result = np.empty(events.shape[0])
          for i in range(events.shape[0]):
              result[i] = distribution(events[i])
          return result

      return vectorized if vectorize else distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:

* Checking out the partonic xs.
Let's set up a cut for the η of the other photon.
#+begin_src jupyter-python :exports both :results raw drawer
  other_eta_cut = -2.5 < CutOtherEta() < 2.5
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  def part_dist(eta):
      if isinstance(eta, np.ndarray):
          return np.array([part_dist(s_η) for s_η in eta])

      if not other_eta_cut([0, eta, .5, 1]):
          return 0
      return diff_xs_η(e_proton, -1 / 3, eta, 0.5, 1)

  part_samples = monte_carlo.sample_unweighted_array(
      100000,
      part_dist,
      interval=[-2.5, 2.5],
      proc="auto",
  )
  part_samples.min()
#+end_src

#+RESULTS:
: -2.499992898428325

#+begin_src jupyter-python :exports both :results raw drawer
part_hist = np.histogram(part_samples, bins=50, range=[-2.5, 2.5])
fig, ax = set_up_plot()
draw_histogram(ax, part_hist)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f2da24a1e80>
[[file:./.ob-jupyter/60624f423d26291605a6802e987362d0b69be208.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_sherpa_part = yoda.read("../../runcards/pp_partonic/analysis/Analysis.yoda")
  sherpa_part_hist = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/eta"])
  draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist),
          dict(hist=part_hist),
      ]
  )
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 2 | Axes> | (<matplotlib.axes._subplots.AxesSubplot at 0x7f2da1b62a30> <matplotlib.axes._subplots.AxesSubplot at 0x7f2da1f5a250>) |
[[file:./.ob-jupyter/328a8fdd25bbfda79fa5fbbb448cff6e9e522401.png]]
:END:

* Total XS
Now, it would be interesting to know the total cross section.

#+begin_src jupyter-python :exports both :results raw drawer
  dist_η_vec, _ = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=(CutpT() > min_pT) & (-1 < CutOtherEta() < 1),
      vectorize=True,
      quarks=np.array([[1, -1 / 3]]),
  )

  xs_int_res, xs_sample = monte_carlo.integrate(
      lambda x: gev_to_pb(dist_η_vec(x)),
      np.array([[-1, 1], [pdf.xMin, 1], [pdf.xMin, 1]]),
      num_points=8000000,
      adapt=False,
      epsilon=0.01,
      return_sample=True,
  )
  xs_int_res.result * np.pi, xs_int_res.sigma * np.pi
#+end_src

#+RESULTS:
:RESULTS:
| 0.0007566292499457039 | 6.319704624358753e-06 |
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:


We use this as upper bound, as the maximizer is bogus because of the
cuts!
#+begin_src jupyter-python :exports both :results raw drawer
  upper_bound = pb_to_gev(xs_sample.max()) * 1.01
  upper_bound
#+end_src

#+RESULTS:
: 5.511597768913529e-10

* Event generation
We set up a new distribution. Look at that cut sugar!
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
  )
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

Plotting it, we can see that the variance is reduced.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax2 = ax.twinx()
  pts = np.linspace(*interval_η, 1000)

  ax.plot(pts, [dist_η(np.array([η, 0.04, 0.04])) for η in pts])
  ax2.plot(pts, [dist_η(np.array([η, 1, .5])) for η in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f64f2cc1670> |
[[file:./.ob-jupyter/a789e914a8b6fcb110b211ea596d41c763ea15e7.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
  pts = np.linspace(0.1, 1, 1000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(2, pt, 2*100**2)/pt for pt in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f650005eb80> |
[[file:./.ob-jupyter/b92f0c4b2c9f2195ae14444748fcdb7708d81c19.png]]
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  intervals_η = np.array([interval_η, [pdf.xMin, 1], [pdf.xMin, 1]])

  result, eff = monte_carlo.sample_unweighted_array(
      1000_000,
      dist_η,
      interval=intervals_η,
      proc="auto",
      report_efficiency=True,
      upper_bound=upper_bound,
      cache="cache/pdf/total_xs_1000_000",
      status_path="/tmp/status1"
  )
  eff
#+end_src

#+RESULTS:
: 0.0005637354643781789

The efficiency is still quite horrible, but at least an order of
mag. better than with cosθ.

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins=50)
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 1000000
[[file:./.ob-jupyter/945936d1fc238435ba26b62be01c02ad3e0d9159.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
gev_to_pb(eff * (intervals_η[:, 1] - intervals_η[:, 0]).prod() * 5.5e-10) * 2*np.pi
#+end_src

#+RESULTS:
: 0.001523927498506122

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  draw_ratio_plot(
      [
          dict(hist=yoda_hist),
          dict(hist=np.histogram(result[:, 0], bins=50, range=interval_η)),
      ]
  )
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 2 | Axes> | (<matplotlib.axes._subplots.AxesSubplot at 0x7f64ebc3b7f0> <matplotlib.axes._subplots.AxesSubplot at 0x7f64ebfe1be0>) |
[[file:./.ob-jupyter/2244aab8e7561c7f21b452d228c37ab328765816.png]]
:END:

That looks OK.

[[mailto:ment@stho.sht][sh]
