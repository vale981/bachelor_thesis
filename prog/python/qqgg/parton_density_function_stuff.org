#+PROPERTY: header-args :exports both :output-dir results :session pdf :kernel python3
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
#+end_src

#+RESULTS:

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
Î· = 2.4
e_proton = 100  # GeV
interval_Î· = [-Î·, Î·]
interval = Î·_to_Î¸([-Î·, Î·])
interval_cosÎ¸ = np.cos(interval)
num_samples = 10_000
#+end_src

#+RESULTS:


* Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  Î³Î³ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosÎ¸):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosÎ¸ = np.asarray(cosÎ¸)
      assert (
          x_1.shape == x_2.shape == cosÎ¸.shape
      ), "Invalid shapes for the event parameters."

      q_1 = (
          e_proton
          ,* x_1
          ,* np.array(
              [
                  np.ones_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.ones_like(cosÎ¸),
              ]
          )
      )
      q_2 = (
          e_proton
          ,* x_2
          ,* np.array(
              [
                  np.ones_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  -np.ones_like(cosÎ¸),
              ]
          )
      )
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (2 * x_2 + (x_1 - x_2) * (1 - cosÎ¸))
          ,* np.array(
              [1 * np.ones_like(cosÎ¸), np.sqrt(1 - cosÎ¸ ** 2), np.zeros_like(cosÎ¸), cosÎ¸]
          )
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosÎ¸.size).T
      q_2 = q_2.reshape(4, cosÎ¸.size).T
      g_3 = g_3.reshape(4, cosÎ¸.size).T
      g_4 = g_4.reshape(4, cosÎ¸.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs(e_proton, charge, cosÎ¸, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the azimuth angle Î¸ of one photon in units of 1/GeVÂ².

      Here dÎ©=d(cosÎ¸)dÏ†

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param cosÎ¸: the angle

      :return: the differential cross section [GeV^{-2}]
      """

      f = energy_factor(e_proton, charge, x_1, x_2)
      return (x_1 ** 2 * (1 - cosÎ¸) ** 2 + x_2 ** 2 * (1 + cosÎ¸) ** 2) / (
          (1 - cosÎ¸ ** 2) * (x_1 * (1 - cosÎ¸) + x_2 * (1 + cosÎ¸))
      )


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_Î·(e_proton, charge, Î·, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity Î· of one photon in units of 1/GeVÂ².

      Here dÎ©=dÎ·dÏ†

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param Î·: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """
      tanh_Î· = np.tanh(Î·)
      f = energy_factor(e_proton, charge, x_1, x_2)

      return (x_1 ** 2 * (1 - tanh_Î·) ** 2 + x_2 ** 2 * (1 + tanh_Î·) ** 2) / (
          x_1 * (1 - tanh_Î·) + x_2 * (1 + tanh_Î·)
      )


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2
#+end_src

#+RESULTS:

* Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  from numba.extending import get_cython_function_address

  def get_xs_distribution_with_pdf(xs, q, e_hadron, quarks=None, pdf=None):
      """Creates a function that takes an event (type np.ndarray) of the
      form [cosÎ¸, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. CosÎ¸ can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, cosÎ¸, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function

      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = quarks or np.array([[2, 2 / 3], [1, -1 / 3]])  # proton
      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      # @jit(float64(float64[4])) Unfortunately that does not work as yet!
      def distribution(event: np.ndarray) -> float:
          cosÎ¸, x_1, x_2 = event

          q2_value = q(e_hadron, x_1, x_2)
          result = 0

          for quark, charge in quarks:
              xs_value = xs(e_hadron, charge, cosÎ¸, x_1, x_2)
              result += (
                  xfxQ2(quark, x_1, q2_value)
                  / x_1
                  ,* xfxQ2(-quark, x_2, q2_value)
                  / x_2
                  ,* xs_value
              )

          return result

      return distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:
* Event generation
Now we go about the bussines of generating events. Currently we
calculate the 4-momentum kinematics twice. Maybe that can be done
nicer.

#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def sample_momenta(num_samples, dist, interval, e_hadron, upper_bound=None, **kwargs):
      res, eff = monte_carlo.sample_unweighted_array(
          num_samples,
          dist,
          interval,
          upper_bound=upper_bound,
          report_efficiency=True,
          ,**kwargs
      )
      cosÎ¸, x_1, x_2 = res.T
      return momenta(e_hadron, x_1[None, :], x_2[None, :], cosÎ¸[None, :]), eff
#+end_src

#+RESULTS:

** Test Driving
Now, let's try it out.
#+begin_src jupyter-python :exports both :results raw drawer
  dist, x_limits = get_xs_distribution_with_pdf(
      diff_xs, averaged_tchanel_q2, e_proton
  )
#+end_src

#+RESULTS:

Let's plot it for some random values ðŸ˜ƒ.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  pts = np.linspace(*interval_cosÎ¸, 1000)

  ax.plot(pts, [dist([cosÎ¸, 0.3, 0.3]) for cosÎ¸ in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f1f47902c10> |
[[file:./.ob-jupyter/f12b49e327ad8ec823397b3bbe910e0d021f4dcd.png]]
:END:

Having set both x to the same value, we get a symmetric distribution as expected.
Just the magnitude is a little startling! The value 1/3 is intentional!

Now we gonna take some samples!
But first we have to find an upper bound, which is expensive!

#+begin_src jupyter-python :exports both :results raw drawer
  intervals = [interval_cosÎ¸, [.01, 1], [.01, 1]]
  upper_bound = monte_carlo.find_upper_bound_vector(dist, intervals)
  upper_bound
#+end_src

#+RESULTS:
: 2171.468698483163

Beware!, this is darn slow, becaus the efficiency is soooo low.
#+begin_src jupyter-python :exports both :results raw drawer

  sample_momenta(
      100,
      dist,
      intervals,
      e_proton,
      upper_bound=upper_bound,
      proc="auto",
      cache="cache/pdf/samp_costh_test",
  )[1]
#+end_src

#+RESULTS:
: 0.00041597900424616594

** Switching Horses: Sampling Î·
We set up a new distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_Î·, x_limits = get_xs_distribution_with_pdf(
      diff_xs_Î·, averaged_tchanel_q2, e_proton
  )
#+end_src

#+RESULTS:

Plotting it, we can see that the variance is reduced.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax2 = ax.twinx()
  pts = np.linspace(*interval_Î·, 1000)

  ax.plot(pts, [dist_Î·([Î·, 0.8, 0.3]) for Î· in pts])
  ax2.plot(pts, [dist_Î·([Î·, 0.3, 0.3]) for Î· in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f1f44296940> |
[[file:./.ob-jupyter/257473d72b7c4ffd6650dd4a736a2feaacac28cb.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0).xfxQ2
  pts = np.linspace(0, 1, 1000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf(.01, pt, 2*100**2) for pt in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f1f4574b0d0> |
[[file:./.ob-jupyter/db6aa636b2795408e0e7b762c7e43ed22136feaf.png]]
:END:


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  intervals_Î· = [interval_Î·, [.01, 1], [.01, 1]]

  result, eff = monte_carlo.sample_unweighted_array(
      num_samples,
      dist_Î·,
      interval=intervals_Î·,
      proc="auto",
      report_efficiency=True,
      cache="cache/pdf/huge",
  )
  result
#+end_src

#+RESULTS:
: array([[ 2.00392989,  0.03589851,  0.13781655],
:        [-0.77083958,  0.01088047,  0.1545276 ],
:        [-1.36224887,  0.02099844,  0.05346773],
:        ...,
:        [-0.22217984,  0.01724194,  0.06289104],
:        [-1.26972433,  0.23321426,  0.01352318],
:        [ 1.76699256,  0.01239091,  0.10577669]])



The efficiency is still quite horrible, but at least an order of
mag. better than with cosÎ¸.

Geez. I'd hate having to run this more than once. Let's write it to a
file.

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  draw_histo_auto(result[:, 0], "asht", bins=100)
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 1 | Axes> | <matplotlib.axes._subplots.AxesSubplot | at | 0x7f1f3dd9f340> |
[[file:./.ob-jupyter/3658a99592960354e2b5997443ea0a9de8426d9a.png]]
:END:
