#+PROPERTY: header-args :exports both :output-dir results :session pdf :kernel python3
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
#+end_src

#+RESULTS:

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
η = 2.5
e_proton = 6500  # GeV
interval_η = [-η, η]
interval = η_to_θ([-η, η])
interval_cosθ = np.cos(interval)
num_samples = 10_000
#+end_src

#+RESULTS:

* Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2


  def cut_pT_from_eta(greater_than=0):
      def cut(e_proton, η, x1, x2):
          cosθ = np.cos(η_to_θ(η))
          _, _, p1, p2 = momenta(e_proton, x1, x2, cosθ)
          return (
              np.sqrt((p1[0][1:3] ** 2).sum()) > greater_than
              and np.sqrt((p2[0][1:3] ** 2).sum()) > greater_than
          )

      return cut
#+end_src

#+RESULTS:

* Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2) / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs, q, e_hadron, quarks=None, pdf=None, cut=None, num_points_pdf=1000
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = quarks or np.array(
          # [[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]]
          [[2, 2 / 3]]
      )  # proton
      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      quarks = [
          (
              cached_pdf(pdf, quark, num_points_pdf, e_hadron),
              cached_pdf(pdf, -quark, num_points_pdf, e_hadron),
              quark,
              charge,
          )
          for quark, charge in quarks
      ]
      xfxQ2 = pdf.xfxQ2

      # @jit(float64(float64[4])) Unfortunately that does not work as yet!
      def distribution(event: np.ndarray) -> float:
          if cut and not cut(e_hadron, *event):
              return 0

          angle_arg, x_1, x_2 = event

          q2_value = q(e_hadron, x_1, x_2)
          result = 0

          for fx, fx_bar, quark, charge in quarks:
              xs_value = xs(e_hadron, charge, angle_arg, x_1, x_2)
              result += (
                  (fx(x_1, q2_value) + fx_bar(x_1, q2_value))
                  ,* (fx(x_2, q2_value) + fx_bar(x_2, q2_value))
                  ,* xs_value
              )

          return result

      return distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:
* Event generation
Now we go about the bussines of generating events. Currently we
calculate the 4-momentum kinematics twice. Maybe that can be done
nicer.

#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def sample_momenta(num_samples, dist, interval, e_hadron, upper_bound=None, **kwargs):
      res, eff = monte_carlo.sample_unweighted_array(
          num_samples,
          dist,
          interval,
          upper_bound=upper_bound,
          report_efficiency=True,
          ,**kwargs
      )
      cosθ, x_1, x_2 = res.T
      return momenta(e_hadron, x_1[None, :], x_2[None, :], cosθ[None, :]), eff
#+end_src

#+RESULTS:

** Switching Horses: Sampling η
We set up a new distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      diff_xs_η,
      averaged_tchanel_q2,
      e_proton,
      cut=cut_pT_from_eta(greater_than=20),
      num_points_pdf=100000,
  )
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

Plotting it, we can see that the variance is reduced.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax2 = ax.twinx()
  pts = np.linspace(*interval_η, 1000)

  ax.plot(pts, [dist_η([η, 0.01, 0.01]) for η in pts])
  ax2.plot(pts, [dist_η([η, 1, .1]) for η in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7fb864cab100> |
[[file:./.ob-jupyter/24835817fa62af4261c1048f357ed0dd260d85ac.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
  pts = np.linspace(0.1, 1, 1000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(1, pt, 2*100**2)/pt for pt in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7fb864fe6af0> |
[[file:./.ob-jupyter/4c408dadcdda545d2729103f469d0bcf451c11f9.png]]
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  intervals_η = [interval_η, [.0001, 1], [.0001, 1]]

  result, eff = monte_carlo.sample_unweighted_array(
      1000,
      dist_η,
      interval=intervals_η,
      proc="auto",
      report_efficiency=True,
      #cache="cache/pdf/huge",
  )
  eff
#+end_src

#+RESULTS:
: 0.09020531342524235



The efficiency is still quite horrible, but at least an order of
mag. better than with cosθ.

Geez. I'd hate having to run this more than once. Let's write it to a
file.

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins=50)
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 1000
[[file:./.ob-jupyter/56b3f43c3f682f752a3933f9691996991b23dcaa.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  draw_ratio_plot(
      [
          dict(hist=yoda_hist, errorbars=True),
          dict(hist=np.histogram(result[:, 0], bins=50, range=interval_η)),
      ]
  )
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 2 | Axes> | (<matplotlib.axes._subplots.AxesSubplot at 0x7fb86471ae20> <matplotlib.axes._subplots.AxesSubplot at 0x7fb864622220>) |
[[file:./.ob-jupyter/511b1599917080f0ce611c46929b4c09de0e81a3.png]]
:END:


#+begin_src jupyter-python :exports both :results raw drawer
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(q, x_min + (x_max - x_min) * x / points, Q2_max / points * Q2)
                  for Q2 in range(points)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * points / Q2_max - 1)
          ]

      return cached


  test = cached_pdf(pdf, 2, 1000, e_proton)
  # %timeit test(0)
  # %timeit pdf.xfxQ2(2, 0, e_proton/2)
  %timeit test(.001, e_proton**2)
#+end_src

#+RESULTS:
: 858 ns ± 10.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
