#+PROPERTY: header-args :exports both :output-dir results :kernel python3 :session :session pdf
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
  import lhapdf
#+end_src

#+RESULTS:
: Welcome to JupyROOT 6.20/04

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
  η = 1
  min_pT = 20
  e_proton = 6500  # GeV
  interval_η = [-η, η]
  interval = η_to_θ([-η, η])
  interval_cosθ = np.cos(interval)
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

We gonna export that for reference in the tex document.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(min_pT, prefix=r"\pt \geq ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "min_pT.tex"))
  tex_value(e_proton, prefix=r"E_p = ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "e_proton.tex"))
  tex_value(η, prefix=r"\abs{\eta} \leq ", prec=0, save=("results/pdf/", "eta.tex"))
#+end_src


#+RESULTS:
: \(\abs{\eta} \leq 1\)

* Implementation
** Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64, boolean
  import lab_xs.lab_xs as c_xs


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  class Cut:
      def __init__(self):
          self._other = None
          self._current_comb = self._call

          self._greater_than = 0
          self._lower_than = np.inf

      def __gt__(self, greater_than):
          self._greater_than = greater_than

          return self

      def __lt__(self, lower_than):
          self._lower_than = lower_than

          return self

      def _or_comb(self, event):
          return self._call(event) or self._other(event)

      def _and_comb(self, event):
          return self._call(event) and self._other(event)

      def _call(self, event):
          return self._greater_than < self._calculate(event) < self._lower_than

      def _calculate(self, event):
          raise NotImplementedError('"_calulate" must be implemented.')

      def __call__(self, event):
          return self._current_comb(event)

      def __and__(self, other):
          self._other = other
          self._current_comb = self._and_comb

          return self

      def __or__(self, other):
          self._other = other
          self._current_comb = self._or_comb

          return self

      def apply(self, function):
          @wraps(function)
          def wrapper(event):
              if self(event):
                  return function(event)

              return 0

          return wrapper


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2


  class CutpT(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          e_hadron, eta, x_1, x_2 = event
          return c_xs.pT(e_hadron, eta, x_1, x_2)


  class CutOtherEta(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          _, η, x_1, x_2 = event
          return c_xs.second_eta(η, x_1, x_2)
#+end_src

#+RESULTS:

** Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(
                      q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2
                  )
                  / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs,
      q,
      e_hadron,
      quarks=None,
      pdf=None,
      cut=None,
      num_points_pdf=1000,
      vectorize=False,
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = (
          quarks
          if quarks is not None
          else np.array(
              [[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]]
          )
      )  # all the light quarks

      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      def distribution(angle_arg, x_1, x_2) -> float:
          if cut and not cut([e_hadron, angle_arg, x_1, x_2]):
              return 0

          q2_value = q(e_hadron, x_1, x_2)

          xs_value = xs(e_hadron, 1 / 3, angle_arg, x_1, x_2)
          pdf_values = (
              xfxQ2(quarks[:, 0], x_1, q2_value),
              xfxQ2(-quarks[:, 0], x_1, q2_value),
              xfxQ2(quarks[:, 0], x_2, q2_value),
              xfxQ2(-quarks[:, 0], x_2, q2_value),
          )

          result = 0
          for (quark, charge), q_1, qb_1, q_2, qb_2 in zip(quarks, *pdf_values):
              xs_value = xs(e_hadron, charge, angle_arg, x_1, x_2)

              result += ((q_1 * qb_2) + (qb_1 * q_2)) * xs_value

          return result / (x_1 * x_2)  # identical protons

      def vectorized(angle_arg, x_1, x_2):
          results = np.empty_like(angle_arg)
          for a, x__1, x__2, i in zip(angle_arg, x_1, x_2, range(len(results))):
              results[i] = distribution(a, x__1, x__2)
          return results
      return vectorized if vectorize else distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:

* Checking out the partonic xs.
Let's set up a cut for the η of the other photon and codify our
distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  cut_part = (CutpT() > 2000) & (-2.5 < CutOtherEta() < 2.5)


  def part_dist(eta):
      if isinstance(eta, np.ndarray):
          return np.array([part_dist(s_η) for s_η in eta])

      if not cut_part([e_proton, eta, 0.5, 1]) :
          return 0

      return 2 * np.pi * c_xs.diff_xs_eta(e_proton, -1 / 3, eta, 0.5, 1)
#+end_src

#+RESULTS:

The total cross section is as follows:
#+begin_src jupyter-python :exports both :results raw drawer
  part_xs = monte_carlo.integrate(part_dist, [-2.5, 2.5], epsilon=1e-16)
  part_xs
#+end_src

#+RESULTS:
: IntegrationResult(result=3.323517257035529e-14, sigma=9.569545911748089e-17, N=92356)


We have to convert that to picobarn.
#+begin_src jupyter-python :exports both :results raw drawer
  gev_to_pb(part_xs.result), gev_to_pb(part_xs.sigma)
#+end_src

#+RESULTS:
| 1.2941090629468352e-05 | 3.726183779086256e-08 |

That is compatible with sherpa!
#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part, sherpa_part_σ = np.loadtxt('../../runcards/pp_partonic/sherpa_xs')
  sherpa_part, sherpa_part_σ  # GeV
#+end_src

#+RESULTS:
| 1.29935e-05 | 4.71171e-10 |


We can take some samples as well.
#+begin_src jupyter-python :exports both :results raw drawer
  part_samples = monte_carlo.sample_unweighted_array(
      1000000,
      part_dist,
      interval=[-2.5, 2.5],
      proc="auto",
  )
  part_samples.min()
#+end_src

#+RESULTS:
: -1.8206977316702722

#+begin_src jupyter-python :exports both :results raw drawer
part_hist = np.histogram(part_samples, bins=50, range=[-2.5, 2.5])
fig, ax = set_up_plot()
draw_histogram(ax, part_hist)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f58058c04c0>
[[file:./.ob-jupyter/e309c21aa7ca2778672100a13c49f1e18cbf487c.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_sherpa_part = yoda.read("../../runcards/pp_partonic/analysis/Analysis.yoda")
  sherpa_part_hist = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/eta"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$\eta$")
  xs = np.linspace(-2.5, 2.5, 1000)
  ax.plot(xs, part_dist(xs)/part_xs.result, label="Distribution")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f57fb30a2b0>
[[file:./.ob-jupyter/c213cc58429451a5406dd75073e55f1f1d5e5098.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
  part_momenta = momenta(
      e_proton,
      0.5 * np.ones_like(part_samples),
      1 * np.ones_like(part_samples),
      np.tanh(part_samples),
  )
  part_pt = np.sqrt(part_momenta[2][:,2]**2)
  part_pt_hist = np.histogram(part_pt, bins=50, range=(2000, e_proton))
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part_hist_pT = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist_pT, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_pt_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$p_T$")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f57f944afd0>
[[file:./.ob-jupyter/f8cdffca2a9365041ccd863c3cabcae15f2e7dba.png]]
:END:

* Total XS
Now, it would be interesting to know the total cross section.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η_vec, _ = get_xs_distribution_with_pdf(
        c_xs.diff_xs_eta,
        c_xs.averaged_tchanel_q2,
        e_proton,
        cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
        vectorize=True,
        pdf=pdf,
    )

  xs_int_res = monte_carlo.integrate_vegas_nd(
      lambda η, x_1, x_2: gev_to_pb(2 * np.pi * dist_η_vec(η, x_1, x_2)),
      [interval_η, [pdf.xMin, 1], [pdf.xMin, 1]],
      epsilon=.1,
      proc=1,
      increment_epsilon=1e-4,
      num_increments=8,
      num_points_per_cube=100,
      cache="cache/pdf/total_xs_20",
  )
  xs_int_res
#+end_src

#+RESULTS:
: VegasIntegrationResult(result=9.090188175551319, sigma=0.08688810229559833, N=51200, increment_borders=[array([-1.        , -0.78257005, -0.55648476, -0.27807514,  0.01975403,
:         0.30670953,  0.57178838,  0.79134497,  1.        ]), array([1.00000000e-09, 1.70252890e-03, 2.50770457e-03, 3.38921683e-03,
:        4.45586924e-03, 5.85289775e-03, 8.04482707e-03, 1.77836115e-02,
:        1.00000000e+00]), array([1.00000000e-09, 1.69683906e-03, 2.55969081e-03, 3.54347303e-03,
:        4.70998339e-03, 6.30378969e-03, 9.14433346e-03, 3.16937712e-02,
:        1.00000000e+00])], vegas_iterations=22, maximum=3.61827500866524)

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa, sherpa_σ = np.loadtxt("../../runcards/pp/sherpa_xs")
  sherpa, sherpa_σ  # GeV
#+end_src

#+RESULTS:
| 9.11471 | 0.00712366 |

A factor of two used to be in here. It stemmed from the fact, that
there are two identical protons.

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa-xs_int_res.result
#+end_src

#+RESULTS:
: -0.038950833963138365

We use this as upper bound, as the maximizer is bogus because of the
cuts!
#+begin_src jupyter-python :exports both :results raw drawer
  upper_bound = xs_int_res.maximum
  upper_bound
#+end_src

#+RESULTS:
: 3.61827500866524

That is massive!

So the efficiency will be around:
#+begin_src jupyter-python :exports both :results raw drawer
  upper_bound/xs_int_res.result
#+end_src

#+RESULTS:
: 0.39804181594357285


* Event generation
We set up a new distribution. Look at that cut sugar!
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
      pdf=pdf,
  )

  dist_η_no_cut, _ = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      pdf=pdf,
  )
#+end_src

#+RESULTS:

Now we create an eye-candy surface plot.
#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1, 100)
  ηs = np.linspace(-2.5, 2.5, 100)
  x_2_const = 0.01

  grid_xs, grid_ηs = np.meshgrid(xs, ηs)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut([grid_ηs[i, j], grid_xs[i, j], x_2_const]))
              for i in range(len(ηs))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$\eta$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(grid_xs, grid_ηs, pdf_surface, cmap=cm.coolwarm, linewidth=0)
  #fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_x2_const", "pdf", size=(6, 3.5))
  tex_value(x_2_const, prefix=r"x_2 = ", prec=2, save=("results/pdf/", "second_x.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(x_2 = 0.01\)
[[file:./.ob-jupyter/707cca84798ee2959fc7e0458531b0d5321a012d.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1/4, 100)
  x_2s = np.linspace(0.01, 0.1/4, 100)
  eta_const = 2.5

  grid_xs, grid_x_2s = np.meshgrid(xs, x_2s)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut([eta_const, grid_xs[i, j], grid_x_2s[i, j]]))
              for i in range(len(x_2s))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$x_2$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(
      grid_xs, grid_x_2s, pdf_surface, cmap=cm.coolwarm, linewidth=0
  )
  ax.view_init(30, 20)
  ax.xaxis.set_major_locator(plt.MaxNLocator(5))
  ax.yaxis.set_major_locator(plt.MaxNLocator(5))
  # fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_eta_const", "pdf", size=(6, 3.5))
  tex_value(eta_const, prefix=r"\eta = ", prec=2, save=("results/pdf/", "plot_eta.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(\eta = 2.50\)
[[file:./.ob-jupyter/585a2bba902512d5328c3f8c474f6436a3992a5c.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.linspace(0.1, 1, 1000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(2, pt, 2*100**2)/pt for pt in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7fd424f1aca0> |
[[file:./.ob-jupyter/b92f0c4b2c9f2195ae14444748fcdb7708d81c19.png]]
:END:


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  intervals_η = np.array([interval_η, [pdf.xMin, 1], [pdf.xMin, 1]])

  result, eff = monte_carlo.sample_unweighted_array(
      1_000,
      dist_η,
      interval=intervals_η,
      proc="auto",
      report_efficiency=True,
      upper_bound=upper_bound,
      #cache="cache/pdf/total_xs_1000_000",
      status_path="/tmp/status1"
  )
  eff
#+end_src

#+RESULTS:
: 0.001043054794298712

The efficiency is still quite horrible, but at least an order of
mag. better than with cosθ.

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins=50)
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 1000
[[file:./.ob-jupyter/227bd8b1016afb1a90199937e140b7e8dd97d0f8.png]]
:END:

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp_sherpa_299_port/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  fig, (ax, _) = draw_ratio_plot(
      [
          dict(hist=yoda_hist, hist_kwargs=dict(label="sherpa")),
          dict(hist=np.histogram(result[:, 0], bins=50, range=interval_η)),
          #dict(hist=np.histogram(sherpa_manual, bins=50, range=interval_η), hist_kwargs=dict(label="sherpa")),
      ]
  )
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fd42575f1f0>
[[file:./.ob-jupyter/2242e340857b4cd5f3f339845eeadaddac9bf3b3.png]]
:END:

Hah! there we have it!

#+begin_src jupyter-python :exports both :results raw drawer
  mom = momenta(e_proton, result[:,1], result[:,2], np.tanh(result[:,0]))[2]
#+end_src

#+RESULTS:


#+begin_src jupyter-python :exports both :results raw drawer
  from tangled import observables
  pT_hist = np.histogram(observables.p_t(mom), bins=50, range=(min_pT, e_proton))
  yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, _) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_pt, hist_kwargs=dict(label="sherpa")),
          dict(hist=pT_hist),
          #dict(hist=np.histogram(sherpa_manual, bins=50, range=interval_η), hist_kwargs=dict(label="sherpa")),
      ]
  )
  #ax.set_yscale('log')
  ax.set_xscale('log')
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7fd425842700>
[[file:./.ob-jupyter/d2487dbcb40c899d43a24c30e082fb67c2a1f783.png]]
:END:
