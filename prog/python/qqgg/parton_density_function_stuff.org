#+PROPERTY: header-args :exports both :output-dir results :session pdf :kernel python3
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
#+end_src

#+RESULTS:
: Welcome to JupyROOT 6.20/04

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
η = 1
e_proton = 6500  # GeV
interval_η = [-η, η]
interval = η_to_θ([-η, η])
interval_cosθ = np.cos(interval)
num_samples = 10_000
#+end_src

#+RESULTS:

* Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64, boolean
  import lab_xs.lab_xs as c_xs

  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2

  def cut_pT_from_η(greater_than=0):
      def cut(e_proton, η, x_1, x_2):
          return c_xs.pT(e_proton, η, x_1, x_2) > greater_than

      return cut
#+end_src

#+RESULTS:

* Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(
                      q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2
                  )
                  / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs,
      q,
      e_hadron,
      quarks=None,
      pdf=None,
      cut=None,
      num_points_pdf=1000,
      vectorize=False,
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = (
          quarks
          if quarks is not None
          else np.array(
              # [[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]]
              [[1, -1 / 3]]
          )
      )  # all the light quarks

      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      def distribution(event: np.ndarray) -> float:
          if cut and not cut(e_hadron, *event):
              return 0

          angle_arg, x_1, x_2 = event

          q2_value = q(e_hadron, x_1, x_2)
          result = 0

          for quark, charge in quarks:
              xs_value = xs(e_hadron, charge, angle_arg, x_1, x_2)

              result += (
                  (xfxQ2(quark, x_1, q2_value) + xfxQ2(-quark, x_1, q2_value))
                  / x_1
                  ,* (xfxQ2(-quark, x_2, q2_value) + xfxQ2(quark, x_2, q2_value))
                  / x_2
                  ,* xs_value
              )

          return result

      def vectorized(events):
          result = np.empty(events.shape[0])
          for i in range(events.shape[0]):
              result[i] = distribution(events[i])
          return result

      return vectorized if vectorize else distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:
* Event generation
Now we go about the bussines of generating events. Currently we
calculate the 4-momentum kinematics twice. Maybe that can be done
nicer.

#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def sample_momenta(num_samples, dist, interval, e_hadron, upper_bound=None, **kwargs):
      res, eff = monte_carlo.sample_unweighted_array(
          num_samples,
          dist,
          interval,
          upper_bound=upper_bound,
          report_efficiency=True,
          ,**kwargs
      )
      cosθ, x_1, x_2 = res.T
      return momenta(e_hadron, x_1[None, :], x_2[None, :], cosθ[None, :]), eff
#+end_src

#+RESULTS:

We set up a new distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=cut_pT_from_η(greater_than=200),
  )
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

Plotting it, we can see that the variance is reduced.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax2 = ax.twinx()
  pts = np.linspace(*interval_η, 1000)

  ax.plot(pts, [dist_η(np.array([η, 0.04, 0.04])) for η in pts])
  ax2.plot(pts, [dist_η(np.array([η, 1, .1])) for η in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f4a197dd820> |
[[file:./.ob-jupyter/038d0c37fa9e7b737cccb79451c0b89c0a6ea14c.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
  pts = np.linspace(0.1, 1, 1000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(2, pt, 2*100**2)/pt for pt in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f4a195ddbb0> |
[[file:./.ob-jupyter/b92f0c4b2c9f2195ae14444748fcdb7708d81c19.png]]
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  intervals_η = np.array([interval_η, [pdf.xMin, 1], [pdf.xMin, 1]])

  result, eff = monte_carlo.sample_unweighted_array(
      1000000,
      dist_η,
      interval=intervals_η,
      proc="auto",
      report_efficiency=True,
      upper_bound=5.5e-10,
      cache="cache/pdf/huge11",
      status_path="/tmp/status1"
  )
  eff
#+end_src

#+RESULTS:
: 0.0010013294558830314

The efficiency is still quite horrible, but at least an order of
mag. better than with cosθ.
#+begin_src jupyter-python :exports both :results raw drawer
xmin = 20/((1-np.tanh(η)**2)*e_proton) +.08
dist_η([-η, xmin, xmin])
#+end_src

#+RESULTS:
: 4.6926779419045556e-12

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins=50)
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 1000000
[[file:./.ob-jupyter/0069de20eb1b8baa50a5343fd30c79c683a1fab1.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
gev_to_pb(eff * (intervals_η[:, 1] - intervals_η[:, 0]).prod() * 5.5e-10) * 2*np.pi
#+end_src

#+RESULTS:
: 0.002694774847491895

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  draw_ratio_plot(
      [
          dict(hist=yoda_hist),
          dict(hist=np.histogram(result[:, 0], bins=50, range=interval_η)),
      ]
  )
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 2 | Axes> | (<matplotlib.axes._subplots.AxesSubplot at 0x7f4a19670e80> <matplotlib.axes._subplots.AxesSubplot at 0x7f4a193e42e0>) |
[[file:./.ob-jupyter/7cb88ad6d47c5257514683853b4d63dbe3d9c349.png]]
:END:

That looks OK.

** Total XS
Now, it would be interesting to know the total cross section.
#+begin_src jupyter-python :exports both :results raw drawer
import scipy.integrate
scipy.integrate.quad(lambda x: gev_to_pb(dist_η(x)), intervals_η[:, 0], intervals_η[:, 1], workers=8)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: TypeError                                 Traceback (most recent call last)
: <ipython-input-15-ffdad84e393c> in <module>
:       1 import scipy.integrate
: ----> 2 scipy.integrate.quad(lambda x: gev_to_pb(dist_η(x)), intervals_η[:, 0], intervals_η[:, 1], workers=8)
:
: TypeError: quad() got an unexpected keyword argument 'workers'
:END:


#+begin_src jupyter-python :exports both :results raw drawer
  dist_η_vec, _ = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=cut_pT_from_η(greater_than=200),
      vectorize=True,
      quarks=np.array([[1, -1/3]])
  )

  xs_int_res = monte_carlo.integrate(
      lambda x: gev_to_pb(dist_η_vec(x)),
      np.array([[-1, 1], [pdf.xMin, 1], [pdf.xMin, 1]]),
      num_points=800000,
      adapt=False,
      epsilon=0.01,
  )
  xs_int_res.result*2*np.pi, xs_int_res.sigma*2*np.pi
  xs_int_res
#+end_src

#+RESULTS:
:RESULTS:
: 0.20826397472383126 [[-0.4523158   0.0201646   0.04736293]]
: IntegrationResult(result=0.00042109900435229747, sigma=7.494522882354145e-06, N=800000)
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:

: 692.839178467359

: IntegrationResult(result=3.948923167147158, sigma=0.15482356147217707, N=8000000)
: IntegrationResult(result=3.8164729865795977, sigma=0.2263485810566686, N=3000000)

#+begin_src jupyter-python :exports both :results raw drawer
 xs_int_res
#+end_src

#+RESULTS:
: IntegrationResult(result=0.00042109900435229747, sigma=7.494522882354145e-06, N=800000)


#+begin_src jupyter-python :exports both :results raw drawer
%timeit diff_xs_η(1,2,3,4,5)
#+end_src

#+RESULTS:
: 3.9 µs ± 75.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)

#+begin_src jupyter-python :exports both :results raw drawer
dist_η([-0.54149063, 0.01765461, 0.05391543])
#+end_src

#+RESULTS:
: 5.377390723815607e-10

#+begin_src jupyter-python :exports both :results raw drawer
 test_eta = -5
 test_θ = η_to_θ(test_eta)
 momenta(e_proton, .5, .5, np.cos(test_θ))[2][0][2]
#+end_src

#+RESULTS:
: 43.79466721924628

#+begin_src jupyter-python :exports both :results raw drawer
c_xs.pT(e_proton, test_eta, .5, .5)
#+end_src

#+RESULTS:
: 43.79466721924628



*** Troubleshooting
Sherpas Values are:

#+begin_src jupyter-python :exports both :results raw drawer
  xa = 0.0402345
  xb = 0.0357691
  Q = 348.724
  ME = 1.58989334360387e-08
  sherpa_mom = np.array(
      [
          (261.524150231736, 0, 0, -261.524150231736),
          (232.498927281197, 0, 0, 232.498927281197),
          (249.235444881315, 151.716992649161, -190.678302527712, -52.3645497625224),
          (244.787632631618, -151.716992649161, 190.678302527712, 23.339326811983),
      ]
  )

  sherpa_cosθ = sherpa_mom[2][3] / sherpa_mom[2][0]
  sherpa_cosθ
#+end_src

#+RESULTS:
: -0.21010073341477656

#+begin_src jupyter-python :exports both :results raw drawer
 xa*e_proton
#+end_src

#+RESULTS:
: 261.52425

#+begin_src jupyter-python :exports both :results raw drawer
 2*xa*xb*e_proton**2
#+end_src

#+RESULTS:
: 121608.331658775

#+begin_src jupyter-python :exports both :results raw drawer
((sherpa_mom[0][0]+sherpa_mom[1][0])**2-(sherpa_mom[0][3]+sherpa_mom[1][3])**2)/2
#+end_src

#+RESULTS:
: 121608.16877401047

#+begin_src jupyter-python :exports both :results raw drawer
Q**2
#+end_src

#+RESULTS:
: 121608.42817599999


#+begin_src jupyter-python :exports both :results raw drawer
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)


  def evalpdf(x1, x2, q):
      return pdf.xfxQ2(1, x1, q ** 2) * pdf.xfxQ2(-1, x2, q ** 2) / (x1 * x2)


  evalpdf(xa, xb, Q)
#+end_src

#+RESULTS:
:RESULTS:
: 106.61430276022917
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000
:END:

Sherpa gave the same.
Let's look at the kinematics.

#+begin_src jupyter-python :exports both :results raw drawer
  my_mom = momenta(e_proton, xa, xb, sherpa_cosθ)
  my_mom
#+end_src

#+RESULTS:
: array([[[ 261.52425   ,    0.        ,    0.        ,  261.52425   ]],
:
:        [[ 232.49915   ,    0.        ,    0.        , -232.49915   ]],
:
:        [[ 243.15752994,    0.        ,  237.73019162,  -51.08757537]],
:
:        [[ 250.86587006,    0.        , -237.73019162,   80.11267537]]])

Looks OK. Let's look at the matrix element.

#+begin_src jupyter-python :exports both :results raw drawer
((my_mom[2][0][0]+my_mom[3][0][0])**2-(my_mom[2][0][3]+my_mom[3][0][3])**2)/2
#+end_src

#+RESULTS:
: 121608.33165877499

#+begin_src jupyter-python :exports both :results raw drawer
((sherpa_mom[2][0]+sherpa_mom[3][0])**2-(sherpa_mom[2][3]+sherpa_mom[3][3])**2)/2
#+end_src

#+RESULTS:
: 121608.16877401045


#+begin_src jupyter-python :exports both :results raw drawer
ME
#+end_src

#+RESULTS:
: 1.58989334360387e-08

#+begin_src jupyter-python :exports both :results raw drawer
MY_ME = 4/3*(np.sqrt(4*np.pi*1/137.036)*(1/3))**4*(1+sherpa_cosθ**2)/(1-sherpa_cosθ**2)
MY_ME/ME
#+end_src

#+RESULTS:
: 9510.482941946759

Why!

I checked back with the d, dbar process. The ME there has a weird factor ~1/20**4~
#+begin_src jupyter-python :exports both :results raw drawer
  c=-93.8879722861009/100
  4/3*(np.sqrt(4*np.pi*1/137.036)*(1/3)/20)**4*(1+c**2)/(1-c**2)
#+end_src

#+RESULTS:
: 1.373570744771939e-08


#+begin_src jupyter-python :exports both :results raw drawer
  def test(x):
      return x[:,0]*x[:, 1]

  monte_carlo.integrate(test, [[0,1], [0,1]], epsilon=.0001)
  #test(np.array([[1,2],[1,1]]))
#+end_src

#+RESULTS:
:RESULTS:
: 0.9997155172485124 [[0.99999095 0.99972456]]
: IntegrationResult(result=0.2499698460592311, sigma=9.536202506031499e-05, N=5346792)
:END:


Let's see how the pts are distributed:
#+begin_src jupyter-python :exports both :results raw drawer
  sample_mom = momenta(e_proton, result[:,1], result[:,2], np.cos(η_to_θ(result[:,0])))[2]
  sample_pts = np.sqrt(sample_mom[:,1]**2 + sample_mom[:,2]**2)
  sample_pts.min()
#+end_src

#+RESULTS:
: 200.00006712310318

Looks ok.
