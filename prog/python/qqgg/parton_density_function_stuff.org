#+PROPERTY: header-args :exports both :output-dir results :kernel python3 :session :session pdf
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
  import yoda
  import lhapdf
#+end_src

#+RESULTS:

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%aimport tangled
from tangled import observables
%autoreload 1
#+END_SRC

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
  η = 2.5
  min_pT = 20
  e_proton = 6500  # GeV
  interval_η = [-η, η]
  interval = η_to_θ([-η, η])
  interval_cosθ = np.cos(interval)
  pdf = lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
#+end_src

#+RESULTS:
: LHAPDF 6.2.3 loading /usr/share/lhapdf/LHAPDF/NNPDF31_lo_as_0118/NNPDF31_lo_as_0118_0000.dat
: NNPDF31_lo_as_0118 PDF set, member #0, version 1; LHAPDF ID = 315000

We gonna export that for reference in the tex document.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(min_pT, prefix=r"\pt \geq ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "min_pT.tex"))
  tex_value(e_proton, prefix=r"E_p = ", prec=0, unit=r"\giga\electronvolt", save=("results/pdf/", "e_proton.tex"))
  tex_value(η, prefix=r"\abs{\eta} \leq ", prec=0, save=("results/pdf/", "eta.tex"))
#+end_src


#+RESULTS:
: \(\abs{\eta} \leq 2\)

* Implementation
** Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  γγ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64, boolean
  import lab_xs.lab_xs as c_xs


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosθ, φ=None):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosθ = np.asarray(cosθ)

      if φ is None:
          φ = 0
          cosφ = np.ones_like(cosθ)
          sinφ = 0

      else:
          if φ == "rand":
              φ = np.random.uniform(0, 2 * np.pi, cosθ.shape)
          else:
              φ = np.asarray(φ)
          sinφ = np.sin(φ)
          cosφ = np.cos(φ)

      assert (
          x_1.shape == x_2.shape == cosθ.shape
      ), "Invalid shapes for the event parameters."

      sinθ = np.sqrt(1 - cosθ ** 2)

      ones = np.ones_like(cosθ)
      zeros = np.zeros_like(cosθ)

      q_1 = e_proton * x_1 * np.array([ones, zeros, zeros, ones,])
      q_2 = e_proton * x_2 * np.array([ones, zeros, zeros, -ones,])
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (x_1 + x_2 - (x_1 - x_2) * cosθ)
          ,* np.array([1 * np.ones_like(cosθ), sinθ * sinφ, cosφ * sinθ, cosθ])
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosθ.size).T
      q_2 = q_2.reshape(4, cosθ.size).T
      g_3 = g_3.reshape(4, cosθ.size).T
      g_4 = g_4.reshape(4, cosθ.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_η(e_proton, charge, η, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity η of one photon in units of 1/GeV².

      Here dΩ=dηdφ

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param η: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """

      rap = np.arctanh((x_1 - x_2) / (x_1 + x_2))
      f = energy_factor(e_proton, charge, x_1, x_2)

      return f * ((np.tanh(η - rap)) ** 2 + 1)


  class Cut:
      def __init__(self):
          self._other = None
          self._current_comb = self._call

          self._greater_than = 0
          self._lower_than = np.inf

      def __gt__(self, greater_than):
          self._greater_than = greater_than

          return self

      def __lt__(self, lower_than):
          self._lower_than = lower_than

          return self

      def _or_comb(self, event):
          return self._call(event) or self._other(event)

      def _and_comb(self, event):
          return self._call(event) and self._other(event)

      def _call(self, event):
          return self._greater_than < self._calculate(event) < self._lower_than

      def _calculate(self, event):
          raise NotImplementedError('"_calulate" must be implemented.')

      def __call__(self, event):
          return self._current_comb(event)

      def __and__(self, other):
          self._other = other
          self._current_comb = self._and_comb

          return self

      def __or__(self, other):
          self._other = other
          self._current_comb = self._or_comb

          return self

      def apply(self, function):
          @wraps(function)
          def wrapper(event):
              if self(event):
                  return function(event)

              return 0

          return wrapper


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2


  class CutpT(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          e_hadron, eta, x_1, x_2 = event
          return c_xs.pT(e_hadron, eta, x_1, x_2)


  class CutOtherEta(Cut):
      def __init__(self):
          super().__init__()

      def _calculate(self, event):
          _, η, x_1, x_2 = event
          return c_xs.second_eta(η, x_1, x_2)
#+end_src

#+RESULTS:

** Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def cached_pdf(pdf, q, points, e_hadron):
      x_min = pdf.xMin
      x_max = pdf.xMax
      Q2_max = 2 * e_hadron ** 2

      cache = np.array(
          [
              [
                  pdf.xfxQ2(
                      q, xx := x_min + (x_max - x_min) * x / points, Q2_max / 100 * Q2
                  )
                  / xx
                  for Q2 in range(100)
              ]
              for x in range(points)
          ]
      )

      def cached(x, q2):
          return cache[int((x - x_min) / (x_max - x_min) * points - 1)][
              int(q2 * 100 / Q2_max - 1)
          ]

      return cached


  def get_xs_distribution_with_pdf(
      xs,
      q,
      e_hadron,
      quarks=None,
      pdf=None,
      cut=None,
      num_points_pdf=1000,
      vectorize=False,
  ):
      """Creates a function that takes an event (type np.ndarray) of the
      form [angle_arg, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. Angle_Arg can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, angle_arg, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :param cut: cut function with signature (energy hadron, angle_arg, x_1,
      x_2) to return 0, when the event does not fit the cut

      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function
      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = (
          quarks
          if quarks is not None
          else np.array([[5, -1 / 3], [4, 2 / 3], [3, -1 / 3], [2, 2 / 3], [1, -1 / 3]])
      )  # all the light quarks

      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      def distribution(angle_arg, x_1, x_2) -> float:
          if cut and not cut([e_hadron, angle_arg, x_1, x_2]):
              return 0

          q2_value = q(e_hadron, x_1, x_2)

          xs_value = xs(e_hadron, 1 / 3, angle_arg, x_1, x_2)
          pdf_values = (
              xfxQ2(quarks[:, 0], x_1, q2_value),
              xfxQ2(-quarks[:, 0], x_1, q2_value),
              xfxQ2(quarks[:, 0], x_2, q2_value),
              xfxQ2(-quarks[:, 0], x_2, q2_value),
          )

          result = 0
          xs_value = xs(e_hadron, 1, angle_arg, x_1, x_2)

          for (quark, charge), q_1, qb_1, q_2, qb_2 in zip(quarks, *pdf_values):

              result += ((q_1 * qb_2) + (qb_1 * q_2)) * (charge ** 4)

          return result * xs_value / (x_1 * x_2)  # identical protons

      def vectorized(angle_arg, x_1, x_2):
          results = np.empty_like(angle_arg)
          for a, x__1, x__2, i in zip(angle_arg, x_1, x_2, range(len(results))):
              results[i] = distribution(a, x__1, x__2)
          return results

      return vectorized if vectorize else distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:

* Checking out the partonic xs.
Let's set up a cut for the η of the other photon and codify our
distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  cut_part = (CutpT() > 2000) & (-2.5 < CutOtherEta() < 2.5)


  def part_dist(eta):
      if isinstance(eta, np.ndarray):
          return np.array([part_dist(s_η) for s_η in eta])

      if not cut_part([e_proton, eta, 0.5, 1]) :
          return 0

      return 2 * np.pi * c_xs.diff_xs_eta(e_proton, -1 / 3, eta, 0.5, 1)
#+end_src

#+RESULTS:

The total cross section is as follows:
#+begin_src jupyter-python :exports both :results raw drawer
  part_xs = monte_carlo.integrate(part_dist, [-2.5, 2.5], epsilon=1e-16)
  part_xs
#+end_src

#+RESULTS:
: IntegrationResult(result=3.3263355021107163e-14, sigma=9.606918774200757e-17, N=91621)


We have to convert that to picobarn.
#+begin_src jupyter-python :exports both :results raw drawer
  gev_to_pb(part_xs.result), gev_to_pb(part_xs.sigma)
#+end_src

#+RESULTS:
| 1.2952064294448379e-05 | 3.740736000804341e-08 |

That is compatible with sherpa!
#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part, sherpa_part_σ = np.loadtxt('../../runcards/pp_partonic/sherpa_xs')
  sherpa_part, sherpa_part_σ  # GeV
#+end_src

#+RESULTS:
| 1.29935e-05 | 4.71171e-10 |


We can take some samples as well.
#+begin_src jupyter-python :exports both :results raw drawer
  part_samples = monte_carlo.sample_unweighted_array(
      1000000,
      part_dist,
      interval=[-2.5, 2.5],
      proc="auto",
  )
  part_samples.min()
#+end_src

#+RESULTS:
: -1.820697046086901

#+begin_src jupyter-python :exports both :results raw drawer
part_hist = np.histogram(part_samples, bins=50, range=[-2.5, 2.5])
fig, ax = set_up_plot()
draw_histogram(ax, part_hist)
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.axes._subplots.AxesSubplot at 0x7f8810eecd00>
[[file:./.ob-jupyter/33cc0e76cdba1eac72e25f9d6c4791ce6f57d252.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  yoda_sherpa_part = yoda.read("../../runcards/pp_partonic/analysis/Analysis.yoda")
  sherpa_part_hist = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/eta"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$\eta$")
  xs = np.linspace(-2.5, 2.5, 1000)
  ax.plot(xs, part_dist(xs)/part_xs.result, label="Distribution")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f8810f48760>
[[file:./.ob-jupyter/48b37fc33b5b35345d6f1144394854e73c09dcc4.png]]
:END:
#+begin_src jupyter-python :exports both :results raw drawer
  part_momenta = momenta(
      e_proton,
      0.5 * np.ones_like(part_samples),
      1 * np.ones_like(part_samples),
      np.tanh(part_samples),
  )
  part_pt = np.sqrt(part_momenta[2][:,2]**2)
  part_pt_hist = np.histogram(part_pt, bins=50, range=(2000, e_proton))
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa_part_hist_pT = yoda_to_numpy(yoda_sherpa_part["/MC_DIPHOTON_PARTONIC/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=sherpa_part_hist_pT, hist_kwargs=dict(label="Sherpa")),
          dict(hist=part_pt_hist, hist_kwargs=dict(label="Own Implementation")),
      ]
  )
  ax_ratio.set_xlabel(r"$p_T$")
  ax.legend()
#+end_src

#+RESULTS:
:RESULTS:
: <matplotlib.legend.Legend at 0x7f8810f698e0>
[[file:./.ob-jupyter/24e2f130a964e8350de92e594129eda6f31b430f.png]]
:END:

* Total XS
Now, it would be interesting to know the total cross section.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η_vec, _ = get_xs_distribution_with_pdf(
        c_xs.diff_xs_eta,
        c_xs.averaged_tchanel_q2,
        e_proton,
        cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
        vectorize=True,
        pdf=pdf,
    )

  xs_int_res = monte_carlo.integrate_vegas_nd(
      lambda η, x_1, x_2: gev_to_pb(2 * np.pi * dist_η_vec(η, x_1, x_2)),
      [interval_η, [pdf.xMin, 1], [pdf.xMin, 1]],
      epsilon=.1,
      proc=1,
      increment_epsilon=1e-2,
      alpha=1.8,
      num_increments=[4, 100, 100],
      num_points_per_cube=10,
      cache="cache/pdf/total_xs_2_5_20_take14",
  )

  xs_int_res
#+end_src

#+RESULTS:
:RESULTS:
: Loading Cache:  integrate_vegas_nd
#+begin_example
  VegasIntegrationResult(result=38.76686716290583, sigma=0.08880441917426432, N=800000, increment_borders=[array([-2.5       , -1.24245433,  0.04299411,  1.32476542,  2.5       ]), array([1.00000000e-09, 3.31306006e-04, 4.18827132e-04, 4.80054877e-04,
         5.35758862e-04, 5.93098306e-04, 6.50055278e-04, 7.08449136e-04,
         7.69011466e-04, 8.32251788e-04, 8.97984345e-04, 9.66350952e-04,
         1.03737969e-03, 1.11055691e-03, 1.18787510e-03, 1.26938455e-03,
         1.35412741e-03, 1.44373759e-03, 1.53660855e-03, 1.63458968e-03,
         1.73470551e-03, 1.83927848e-03, 1.94911399e-03, 2.06310480e-03,
         2.18299327e-03, 2.30800703e-03, 2.43789945e-03, 2.57556000e-03,
         2.71848543e-03, 2.86597838e-03, 3.01932364e-03, 3.17985960e-03,
         3.34928380e-03, 3.51952700e-03, 3.69760645e-03, 3.88532807e-03,
         4.07889953e-03, 4.27965901e-03, 4.49080369e-03, 4.71084243e-03,
         4.93581267e-03, 5.16797385e-03, 5.41121381e-03, 5.66614690e-03,
         5.92548255e-03, 6.18892026e-03, 6.46390008e-03, 6.75176205e-03,
         7.04603677e-03, 7.34574392e-03, 7.65759454e-03, 7.98374224e-03,
         8.32063021e-03, 8.67136924e-03, 9.03866517e-03, 9.41808123e-03,
         9.81313613e-03, 1.02261337e-02, 1.06601953e-02, 1.11043080e-02,
         1.15606536e-02, 1.20325758e-02, 1.25241740e-02, 1.30332809e-02,
         1.35518397e-02, 1.40871794e-02, 1.46319838e-02, 1.51866178e-02,
         1.57726338e-02, 1.63749152e-02, 1.69946614e-02, 1.76368613e-02,
         1.82816303e-02, 1.89484929e-02, 1.96333514e-02, 2.03188025e-02,
         2.10181999e-02, 2.17325887e-02, 2.24736879e-02, 2.32397531e-02,
         2.40232205e-02, 2.47971066e-02, 2.56284006e-02, 2.65395564e-02,
         2.74560803e-02, 2.82783460e-02, 2.92295927e-02, 3.02842068e-02,
         3.12828819e-02, 3.23521544e-02, 3.36451309e-02, 3.51301059e-02,
         3.66716786e-02, 3.87816557e-02, 4.11195139e-02, 4.44417657e-02,
         4.91549183e-02, 5.60922213e-02, 6.96492451e-02, 1.15519360e-01,
         1.00000000e+00]), array([1.00000000e-09, 3.48752363e-04, 4.29960083e-04, 4.89121565e-04,
         5.46359169e-04, 6.04336123e-04, 6.63377930e-04, 7.25125302e-04,
         7.88416797e-04, 8.53204938e-04, 9.20651006e-04, 9.91610473e-04,
         1.06527982e-03, 1.14071019e-03, 1.22080816e-03, 1.30646103e-03,
         1.39733636e-03, 1.49142827e-03, 1.59020915e-03, 1.69408421e-03,
         1.80328015e-03, 1.91766435e-03, 2.03691898e-03, 2.16060080e-03,
         2.28802193e-03, 2.42124534e-03, 2.56162649e-03, 2.70763202e-03,
         2.85953248e-03, 3.01886310e-03, 3.18611382e-03, 3.36027721e-03,
         3.54135713e-03, 3.72849710e-03, 3.92439821e-03, 4.12678743e-03,
         4.33771242e-03, 4.55944106e-03, 4.78772630e-03, 5.02272507e-03,
         5.26685754e-03, 5.52085953e-03, 5.78241709e-03, 6.05653630e-03,
         6.34213969e-03, 6.64019229e-03, 6.94441919e-03, 7.25830899e-03,
         7.58301534e-03, 7.91691935e-03, 8.26651811e-03, 8.62759176e-03,
         8.99338683e-03, 9.37780833e-03, 9.77810801e-03, 1.01959217e-02,
         1.06294652e-02, 1.10689653e-02, 1.15297343e-02, 1.20135796e-02,
         1.25061880e-02, 1.30087281e-02, 1.35343548e-02, 1.40734320e-02,
         1.46233278e-02, 1.51776500e-02, 1.57544645e-02, 1.63572297e-02,
         1.69761438e-02, 1.76140487e-02, 1.82728025e-02, 1.89494108e-02,
         1.96399038e-02, 2.03453247e-02, 2.10582143e-02, 2.17689774e-02,
         2.25023482e-02, 2.32649091e-02, 2.40327041e-02, 2.47671831e-02,
         2.55464331e-02, 2.63903585e-02, 2.73041074e-02, 2.81670599e-02,
         2.90306653e-02, 2.99262321e-02, 3.08054185e-02, 3.19052398e-02,
         3.29917339e-02, 3.41698091e-02, 3.52378841e-02, 3.64530568e-02,
         3.76903007e-02, 3.93030119e-02, 4.14428352e-02, 4.40240008e-02,
         4.81521010e-02, 5.45639259e-02, 6.59420830e-02, 9.74372870e-02,
         1.00000000e+00])], vegas_iterations=7, maximum=13533.774059596946)
#+end_example
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa, sherpa_σ = np.loadtxt("../../runcards/pp/sherpa_xs")
  sherpa, sherpa_σ  # GeV
#+end_src

#+RESULTS:
| 38.7275 | 0.0280886 |

A factor of two used to be in here. It stemmed from the fact, that
there are two identical protons.

#+begin_src jupyter-python :exports both :results raw drawer
  sherpa-xs_int_res.result
#+end_src

#+RESULTS:
: -0.0393671629058332

We use this as upper bound, as the maximizer is bogus because of the
cuts!
#+begin_src jupyter-python :exports both :results raw drawer
  upper_bound = xs_int_res.maximum
  upper_bound
#+end_src

#+RESULTS:
: 13533.774059596946

That is massive!

So the efficiency will be around:
#+begin_src jupyter-python :exports both :results raw drawer
  xs_int_res.result/upper_bound
#+end_src

#+RESULTS:
: 0.0028644535509602235


Let's export those results for TeX:
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(
      ,*xs_int_res.combined_result,
      prefix=r"\sigma = ",
      save=("results/pdf/", "my_sigma.tex"),
      unit=r"\pico\barn"
  )
  tex_value(
      sherpa,
      sherpa_σ,
      prefix=r"\sigma_s = ",
      save=("results/pdf/", "sherpa_sigma.tex"),
      unit=r"\pico\barn",
  )
#+end_src

#+RESULTS:
: \(\sigma_s = \SI{38.728\pm 0.028}{\pico\barn}\)

* Event generation
We set up a new distribution. Look at that cut sugar!
#+begin_src jupyter-python :exports both :results raw drawer
  dist_η, x_limits = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      cut=(CutpT() > min_pT) & (interval_η[0] < CutOtherEta() < interval_η[1]),
      pdf=pdf,
  )

  dist_η_no_cut, _ = get_xs_distribution_with_pdf(
      c_xs.diff_xs_eta,
      c_xs.averaged_tchanel_q2,
      e_proton,
      pdf=pdf,
  )
#+end_src

#+RESULTS:

Now we create an eye-candy surface plot.
#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1, 100)
  ηs = np.linspace(-2.5, 2.5, 100)
  x_2_const = 0.01

  grid_xs, grid_ηs = np.meshgrid(xs, ηs)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut(grid_ηs[i, j], grid_xs[i, j], x_2_const))
              for i in range(len(ηs))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$\eta$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(grid_xs, grid_ηs, pdf_surface, cmap=cm.coolwarm, linewidth=0)
  #fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_x2_const", "pdf", size=(6, 3.5))
  tex_value(x_2_const, prefix=r"x_2 = ", prec=2, save=("results/pdf/", "second_x.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(x_2 = 0.01\)
[[file:./.ob-jupyter/435569ac2b915994a9dda2c14beba363c821370a.png]]
:END:

#+begin_src jupyter-python :exports both :results raw drawer
  from mpl_toolkits.mplot3d import Axes3D
  from matplotlib import cm

  q2 = 100  # GeV

  xs = np.linspace(0.01, 0.1/4, 100)
  x_2s = np.linspace(0.01, 0.1/4, 100)
  eta_const = 2.5

  grid_xs, grid_x_2s = np.meshgrid(xs, x_2s)
  pdf_surface = np.array(
      [
          [
              gev_to_pb(dist_η_no_cut(eta_const, grid_xs[i, j], grid_x_2s[i, j]))
              for i in range(len(x_2s))
          ]
          for j in range(len(xs))
      ]
  ).T

  fig = plt.figure()
  ax = fig.add_subplot(111, projection="3d")
  ax.set_xlabel("$x_1$")
  ax.set_ylabel(r"$x_2$")
  # ax.set_zlabel(r"$d^3\sigma$ [GeV]")

  surface = ax.plot_surface(
      grid_xs, grid_x_2s, pdf_surface, cmap=cm.coolwarm, linewidth=0
  )
  ax.view_init(30, 20)
  ax.xaxis.set_major_locator(plt.MaxNLocator(5))
  ax.yaxis.set_major_locator(plt.MaxNLocator(5))
  # fig.colorbar(surface, shrink=0.5, aspect=5)
  save_fig(fig, "dist3d_eta_const", "pdf", size=(6, 3.5))
  tex_value(eta_const, prefix=r"\eta = ", prec=2, save=("results/pdf/", "plot_eta.tex"))
#+end_src

#+RESULTS:
:RESULTS:
: \(\eta = 2.50\)
[[file:./.ob-jupyter/8bf84cb0460b2d5eb083e20c9fa656723585a030.png]]
:END:

Lets plot how the pdf looks.
#+begin_src jupyter-python :exports both :results raw drawer
  pts = np.logspace(-4, 0, 10000)

  fig, ax = set_up_plot()
  ax.plot(pts, [pdf.xfxQ2(2, pt, 2*100**2)/pt for pt in pts])
  ax.set_yscale('log')
  ax.set_xscale('log')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7fe9d3bd60427cf20af835649efbcbaafefbb3e0.png]]


Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.

#+begin_src jupyter-python :exports both :results raw drawer
  result, eff = monte_carlo.sample_unweighted_array(
      1000_000,
      dist_η,
      increment_borders=np.array(xs_int_res.increment_borders),
      proc="auto",
      report_efficiency=True,
      upper_bound=pb_to_gev(xs_int_res.maximum),
      cache="cache/pdf/total_xs_100_000_2_5_take4",
      status_path="/tmp/status1"
  )
  eff
#+end_src

#+RESULTS:
:RESULTS:
: Loading Cache:  sample_unweighted_array
: 0.00045477019242056083
:END:

The efficiency is still quite horrible, but at least an order of
mag. better than with cosθ.

Let's store the sample size for posterity.
#+begin_src jupyter-python :exports both :results raw drawer
  tex_value(len(result), prefix=r"N=", prec=0, save=("results/pdf/", "sample_size.tex"))
#+end_src

#+RESULTS:
: \(N=1000000\)

** Observables
Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = draw_histo_auto(result[:, 0], r"$\eta$", bins=50)
  #ax.set_yscale('log')
  len(result[:, 0])
#+end_src

#+RESULTS:
:RESULTS:
: 1000000
[[file:./.ob-jupyter/28400cd32cb7dc80b972e7e4a68fdefc029bdfb2.png]]
:END:

Let's use a uniform histogram image size.
#+begin_src jupyter-python :exports both :results raw drawer
  hist_size=(3, 3)
#+end_src

#+RESULTS:

And now we compare all the observables with sherpa.
#+begin_src jupyter-python :exports both :results raw drawer
  yoda_file = yoda.read("../../runcards/pp/analysis/Analysis.yoda")
  yoda_hist = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/eta"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist, hist_kwargs=dict(label="Sherpa")),
          dict(
              hist=np.histogram(result[:, 0], bins=50, range=interval_η),
              hist_kwargs=dict(label="own implementation"),
          ),
      ]
  )
  ax_ratio.set_xlabel(r"$\eta$")
  ax.legend()
  save_fig(fig, "eta_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/43e9d71092ed5ce5c84eab2407a18e988bd527b3.png]]

Hah! there we have it!

#+begin_src jupyter-python :exports both :results raw drawer
  mom = momenta(e_proton, result[:,1], result[:,2], np.tanh(result[:,0]))
#+end_src

#+RESULTS:

pT drops pretty quickly.
#+begin_src jupyter-python :exports both :results raw drawer
  pT_hist = np.histogram(observables.p_t(mom[3]), bins=50, range=(min_pT, e_proton))
  yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_pt, hist_kwargs=dict(label="sherpa")),
          dict(hist=pT_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax.set_yscale("log")
  ax.set_xscale("log")
  ax_ratio.set_xlabel(r"$p_T$ [GeV]")
  ax.legend()
  save_fig(fig, "pt_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/86fbe114dd186ebfb537a218bfb8f0e9f7608df7.png]]

The invariant mass is not constant anymore.
#+begin_src jupyter-python :exports both :results raw drawer
  inv_m_hist = np.histogram(
  observables.inv_m(mom[2], mom[3]), bins=50, range=(2 * min_pT, 2 * e_proton)
  )
  yoda_hist_inv_m = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/inv_m"])

  # yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_inv_m, hist_kwargs=dict(label="sherpa")),
          dict(hist=inv_m_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax.set_yscale("log")
  ax.set_xscale("log")
  ax_ratio.set_xlabel(r"Invariant Mass [GeV]")
  ax.legend()
  save_fig(fig, "inv_m_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ebd50dac92936892f0e1c1869e09010d223ef233.png]]

The cosθ distribution looks more like the paronic one.
#+begin_src jupyter-python :exports both :results raw drawer
  cosθ_hist = np.histogram(
      observables.cosθ(mom[2]), bins=50, range=interval_cosθ
  )
  yoda_hist_cosθ = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/cos_theta"])

  # yoda_hist_pt = yoda_to_numpy(yoda_file["/MC_DIPHOTON_PROTON/pT"])
  fig, (ax, ax_ratio) = draw_ratio_plot(
      [
          dict(hist=yoda_hist_cosθ, hist_kwargs=dict(label="sherpa")),
          dict(hist=cosθ_hist, hist_kwargs=dict(label="own implementation")),
      ]
  )

  ax_ratio.set_xlabel(r"$\cos\theta$")
  ax.legend()
  save_fig(fig, "cos_theta_hist", "pdf", size=hist_size)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/9817f670f0f2ad4574ea62fd5d5ce78e61c5333d.png]]
