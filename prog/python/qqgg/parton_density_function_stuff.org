#+PROPERTY: header-args :exports both :output-dir results :session pdf :kernel python3
#+TITLE: Investigaton of Parton Density Functions
#+AUTHOR: Valentin Boettcher

* Init
** Required Modules
#+begin_src jupyter-python :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  import monte_carlo
#+end_src

#+RESULTS:

** Utilities
#+BEGIN_SRC jupyter-python :exports both
%run ../utility.py
%run tangled/plot_utils.py
%load_ext autoreload
%aimport monte_carlo
%autoreload 1
#+END_SRC

#+RESULTS:

** Global Config
#+begin_src jupyter-python :exports both :results raw drawer
Î· = 2.4
e_proton = 100  # GeV
interval_Î· = [-Î·, Î·]
interval = Î·_to_Î¸([-Î·, Î·])
interval_cosÎ¸ = np.cos(interval)
#+end_src

#+RESULTS:00* Lab Frame XS
We begin by implementing the same sermon for the lab frame.
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  """
  Implementation of the analytical cross section for q q_bar ->
  Î³Î³ in the lab frame.

  Author: Valentin Boettcher <hiro@protagon.space>
  """

  import numpy as np
  import monte_carlo
  import lhapdf
  from numba import jit, vectorize, float64


  @vectorize([float64(float64, float64, float64, float64)], nopython=True)
  def energy_factor(e_proton, charge, x_1, x_2):
      """Calculates the factor common to all other values in this module.

      :param e_proton: proton energy per beam
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark

      """
      return charge ** 4 / (137.036 * e_proton) ** 2 / (24 * x_1 * x_2)


  def momenta(e_proton, x_1, x_2, cosÎ¸):
      """Given the Energy of the incoming protons `e_proton` and the
      momentum fractions `x_1` and `x_2` as well as the cosine of the
      azimuth angle of the first photon the 4-momenta of all particles
      are calculated.
      """
      x_1 = np.asarray(x_1)
      x_2 = np.asarray(x_2)
      cosÎ¸ = np.asarray(cosÎ¸)
      assert (
          x_1.shape == x_2.shape == cosÎ¸.shape
      ), "Invalid shapes for the event parameters."

      q_1 = (
          e_proton
          ,* x_1
          ,* np.array(
              [
                  np.ones_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.ones_like(cosÎ¸),
              ]
          )
      )
      q_2 = (
          e_proton
          ,* x_2
          ,* np.array(
              [
                  np.ones_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  np.zeros_like(cosÎ¸),
                  -np.ones_like(cosÎ¸),
              ]
          )
      )
      g_3 = (
          2
          ,* e_proton
          ,* x_1
          ,* x_2
          / (2 * x_2 + (x_1 - x_2) * (1 - cosÎ¸))
          ,* np.array(
              [1 * np.ones_like(cosÎ¸), np.sqrt(1 - cosÎ¸ ** 2), np.zeros_like(cosÎ¸), cosÎ¸]
          )
      )
      g_4 = q_1 + q_2 - g_3

      q_1 = q_1.reshape(4, cosÎ¸.size).T
      q_2 = q_2.reshape(4, cosÎ¸.size).T
      g_3 = g_3.reshape(4, cosÎ¸.size).T
      g_4 = g_4.reshape(4, cosÎ¸.size).T

      return np.array([q_1, q_2, g_3, g_4])


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs(e_proton, charge, cosÎ¸, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the azimuth angle Î¸ of one photon in units of 1/GeVÂ².

      Here dÎ©=d(cosÎ¸)dÏ†

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param cosÎ¸: the angle

      :return: the differential cross section [GeV^{-2}]
      """

      f = energy_factor(e_proton, charge, x_1, x_2)
      return (x_1 ** 2 * (1 - cosÎ¸) ** 2 + x_2 ** 2 * (1 + cosÎ¸) ** 2) / (
          (1 - cosÎ¸ ** 2) * (x_1 * (1 - cosÎ¸) + x_2 * (1 + cosÎ¸))
      )


  @vectorize([float64(float64, float64, float64, float64, float64)], nopython=True)
  def diff_xs_Î·(e_proton, charge, Î·, x_1, x_2):
      """Calculates the differential cross section as a function of the
      cosine of the pseudo rapidity Î· of one photon in units of 1/GeVÂ².

      Here dÎ©=dÎ·dÏ†

      :param e_proton: proton energy per beam [GeV]
      :param charge: charge of the quark
      :param x_1: momentum fraction of the first quark
      :param x_2: momentum fraction of the second quark
      :param Î·: pseudo rapidity

      :return: the differential cross section [GeV^{-2}]
      """
      tanh_Î· = np.tanh(Î·)
      f = energy_factor(e_proton, charge, x_1, x_2)

      return (x_1 ** 2 * (1 - tanh_Î·) ** 2 + x_2 ** 2 * (1 + tanh_Î·) ** 2) / (
          x_1 * (1 - tanh_Î·) + x_2 * (1 + tanh_Î·)
      )


  @vectorize([float64(float64, float64, float64)], nopython=True)
  def averaged_tchanel_q2(e_proton, x_1, x_2):
      return 2 * x_1 * x_2 * e_proton ** 2
#+end_src

#+RESULTS:

* Tying in the PDF
#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  from numba.extending import get_cython_function_address

  def get_xs_distribution_with_pdf(xs, q, e_hadron, quarks=None, pdf=None):
      """Creates a function that takes an event (type np.ndarray) of the
      form [cosÎ¸, impulse fractions of quarks in hadron 1, impulse
      fractions of quarks in hadron 2] and returns the differential
      cross section for such an event. I would have used an object as
      argument, wasn't for the sampling function that needs a vector
      valued function. CosÎ¸ can actually be any angular-like parameter
      as long as the xs has the corresponding parameter.

      :param xs: cross section function with signature (energy hadron, cosÎ¸, x_1, x_2)
      :param q2: the momentum transfer Q^2 as a function with the signature
      (e_hadron, x_1, x_2)
      :param quarks: the constituent quarks np.ndarray of the form [[id, charge], ...],
      the default is a proton
      :param pdf: the PDF to use, the default is "NNPDF31_lo_as_0118"
      :returns: differential cross section summed over flavors and weighted with the pdfs
      :rtype: function

      """

      pdf = pdf or lhapdf.mkPDF("NNPDF31_lo_as_0118", 0)
      quarks = quarks or np.array([[2, 2 / 3], [1, -1 / 3]])  # proton
      supported_quarks = pdf.flavors()
      for flavor in quarks[:, 0]:
          assert flavor in supported_quarks, (
              "The PDF doesn't support the quark flavor " + flavor
          )

      xfxQ2 = pdf.xfxQ2

      # @jit(float64(float64[4])) Unfortunately that does not work as yet!
      def distribution(event: np.ndarray) -> float:
          cosÎ¸, x_1, x_2 = event

          q2_value = q(e_hadron, x_1, x_2)
          result = 0

          for quark, charge in quarks:
              xs_value = xs(e_hadron, charge, cosÎ¸, x_1, x_2)
              result += (
                  xfxQ2(quark, x_1, q2_value)
                  / x_1
                  ,* xfxQ2(quark, x_2, q2_value)
                  / x_2
                  ,* xs_value
              )

          return result

      return distribution, (pdf.xMin, pdf.xMax)
#+end_src

#+RESULTS:
* Event generation
Now we go about the bussines of generating events. Currently we
calculate the 4-momentum kinematics twice. Maybe that can be done
nicer.

#+begin_src jupyter-python :exports both :results raw drawer :tangle tangled/pdf.py
  def sample_momenta(num_samples, dist, interval, e_hadron, upper_bound=None):
      res, eff = monte_carlo.sample_unweighted_array(
          num_samples, dist, interval, upper_bound=upper_bound, report_efficiency=True
      )
      cosÎ¸, x_1, x_2 = res.T
      return momenta(e_hadron, x_1[None, :], x_2[None, :], cosÎ¸[None, :]), eff
#+end_src

#+RESULTS:

** Test Driving
Now, let's try it out.
#+begin_src jupyter-python :exports both :results raw drawer
  dist, x_limits = get_xs_distribution_with_pdf(
      diff_xs, averaged_tchanel_q2, e_proton
  )
#+end_src

#+RESULTS:

Let's plot it for some random values ðŸ˜ƒ.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  pts = np.linspace(*interval_cosÎ¸, 1000)

  ax.plot(pts, [dist([cosÎ¸, 0.3, 0.3]) for cosÎ¸ in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7fb941cd4b80> |
[[file:./.ob-jupyter/a5954d2e2b47ff630695004830c3de94c2e34723.png]]
:END:

Having set both x to the same value, we get a symmetric distribution as expected.
Just the magnitude is a little startling! The value 1/3 is intentional!

Now we gonna take some samples!
But first we have to find an upper bound, which is expensive!

#+begin_src jupyter-python :exports both :results raw drawer
  intervals = [interval_cosÎ¸, [.01, 1], [.01, 1]]
  upper_bound = monte_carlo.find_upper_bound_vector(dist, intervals)
  upper_bound
#+end_src

#+RESULTS:
: 2786.6683559915655

Beware!, this is darn slow, becaus the efficiency is soooo low.
#+begin_src jupyter-python :exports both :results raw drawer
  sample_momenta(100, dist, intervals, e_proton, upper_bound=upper_bound)[1]
#+end_src

#+RESULTS:
: 0.0011336723125792729

** Switching Horses: Sampling Î·
We set up a new distribution.
#+begin_src jupyter-python :exports both :results raw drawer
  dist_Î·, x_limits = get_xs_distribution_with_pdf(
      diff_xs_Î·, averaged_tchanel_q2, e_proton
  )
#+end_src

#+RESULTS:

Plotting it, we can see that the variance is reduced.
#+begin_src jupyter-python :exports both :results raw drawer
  fig, ax = set_up_plot()
  ax2 = ax.twinx()
  pts = np.linspace(*interval_Î·, 1000)

  ax.plot(pts, [dist_Î·([Î·, 0.8, 0.3]) for Î· in pts])
  ax2.plot(pts, [dist_Î·([Î·, 0.3, 0.3]) for Î· in pts])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f6a34cfd100> |
[[file:./.ob-jupyter/b5e9e8b157f5596913671e301fefee82daf805a9.png]]
:END:

Now we sample some events. Doing this in parallel helps. We let the os
figure out the cpu mapping.
#+begin_src jupyter-python :exports both :results raw drawer
  result = None
  import os.path

  _path = "cache/samples.np"
  if os.path.isfile(_path):
      result = np.fromfile(_path)
      result = result.reshape(result.size // 3, 3)
  else:
      from multiprocessing import Pool
      import os

      intervals_Î· = [interval_Î·, [0.01, 1], [0.01, 1]]

      def _draw(n):
          rand = os.urandom(2)
          return monte_carlo.sample_unweighted_array(
              n, dist_Î·, intervals_Î·, seed=int.from_bytes(rand, "big")
          )

      num_proc = 8
      num_samp = 10_000_000
      with Pool(num_proc) as p:
          result = p.map(_draw, [int(num_samp / num_proc + 1) for _ in range(num_proc)])
          result = np.concatenate(result)
      result.tofile("./cache/samples.np")

  result
#+end_src

#+RESULTS:
: array([[-0.76416103,  0.3008758 ,  0.01946426],
:        [ 1.65764609,  0.28210798,  0.3609708 ],
:        [-2.36590502,  0.20522417,  0.06746521],
:        ...,
:        [ 2.35690164,  0.06437832,  0.14881004],
:        [ 1.52001625,  0.03632975,  0.07488716],
:        [-0.03479727,  0.45513594,  0.02337567]])

The efficiency is still quite horrible, but at least an order of
mag. better than with cosÎ¸.

Geez. I'd hate having to run this more than once. Let's write it to a
file.

Let's look at a histogramm of eta samples.
#+begin_src jupyter-python :exports both :results raw drawer
  draw_histo(result[:, 0], "asht", bins=100)
#+end_src

#+RESULTS:
:RESULTS:
| <Figure | size | 432x288 | with | 1 | Axes> | <matplotlib.axes._subplots.AxesSubplot | at | 0x7f6a2d85a8b0> |
[[file:./.ob-jupyter/667dbb2182e20a5740079a92f769bededd4cf4ee.png]]
:END:

We should take more samples to decrease the Variance. But it takes soooo long.
